// Generated by the gRPC C++ plugin.
// If you make any local change, they will be lost.
// source: tensorflow/core/profiler/profiler_service.proto
#ifndef GRPC_tensorflow_2fcore_2fprofiler_2fprofiler_5fservice_2eproto__INCLUDED
#define GRPC_tensorflow_2fcore_2fprofiler_2fprofiler_5fservice_2eproto__INCLUDED

#include "tensorflow/core/profiler/profiler_service.pb.h"

#include <functional>
#include <grpcpp/impl/codegen/async_generic_service.h>
#include <grpcpp/impl/codegen/async_stream.h>
#include <grpcpp/impl/codegen/async_unary_call.h>
#include <grpcpp/impl/codegen/method_handler_impl.h>
#include <grpcpp/impl/codegen/proto_utils.h>
#include <grpcpp/impl/codegen/rpc_method.h>
#include <grpcpp/impl/codegen/service_type.h>
#include <grpcpp/impl/codegen/status.h>
#include <grpcpp/impl/codegen/stub_options.h>
#include <grpcpp/impl/codegen/sync_stream.h>

namespace grpc {
class CompletionQueue;
class Channel;
class ServerCompletionQueue;
class ServerContext;
}  // namespace grpc

namespace tensorflow {

// The ProfilerService service retrieves performance information about
// the programs running on connected devices over a period of time.
class ProfilerService final {
 public:
  static constexpr char const* service_full_name() {
    return "tensorflow.ProfilerService";
  }
  class StubInterface {
   public:
    virtual ~StubInterface() {}
    // Starts a profiling session, blocks until it completes, and returns data.
    virtual ::grpc::Status Profile(::grpc::ClientContext* context, const ::tensorflow::ProfileRequest& request, ::tensorflow::ProfileResponse* response) = 0;
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ProfileResponse>> AsyncProfile(::grpc::ClientContext* context, const ::tensorflow::ProfileRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ProfileResponse>>(AsyncProfileRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ProfileResponse>> PrepareAsyncProfile(::grpc::ClientContext* context, const ::tensorflow::ProfileRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ProfileResponse>>(PrepareAsyncProfileRaw(context, request, cq));
    }
    // Signal to terminate the Profile rpc for a on-going profiling session,
    // The Profile rpc will return successfully and prematurely without timeout.
    // This is used by programmatic mode to end the session in workers.
    virtual ::grpc::Status Terminate(::grpc::ClientContext* context, const ::tensorflow::TerminateRequest& request, ::tensorflow::TerminateResponse* response) = 0;
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::TerminateResponse>> AsyncTerminate(::grpc::ClientContext* context, const ::tensorflow::TerminateRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::TerminateResponse>>(AsyncTerminateRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::TerminateResponse>> PrepareAsyncTerminate(::grpc::ClientContext* context, const ::tensorflow::TerminateRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::TerminateResponse>>(PrepareAsyncTerminateRaw(context, request, cq));
    }
    // Collects profiling data and returns user-friendly metrics.
    virtual ::grpc::Status Monitor(::grpc::ClientContext* context, const ::tensorflow::MonitorRequest& request, ::tensorflow::MonitorResponse* response) = 0;
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::MonitorResponse>> AsyncMonitor(::grpc::ClientContext* context, const ::tensorflow::MonitorRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::MonitorResponse>>(AsyncMonitorRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::MonitorResponse>> PrepareAsyncMonitor(::grpc::ClientContext* context, const ::tensorflow::MonitorRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::MonitorResponse>>(PrepareAsyncMonitorRaw(context, request, cq));
    }
    class experimental_async_interface {
     public:
      virtual ~experimental_async_interface() {}
      // Starts a profiling session, blocks until it completes, and returns data.
      virtual void Profile(::grpc::ClientContext* context, const ::tensorflow::ProfileRequest* request, ::tensorflow::ProfileResponse* response, std::function<void(::grpc::Status)>) = 0;
      // Signal to terminate the Profile rpc for a on-going profiling session,
      // The Profile rpc will return successfully and prematurely without timeout.
      // This is used by programmatic mode to end the session in workers.
      virtual void Terminate(::grpc::ClientContext* context, const ::tensorflow::TerminateRequest* request, ::tensorflow::TerminateResponse* response, std::function<void(::grpc::Status)>) = 0;
      // Collects profiling data and returns user-friendly metrics.
      virtual void Monitor(::grpc::ClientContext* context, const ::tensorflow::MonitorRequest* request, ::tensorflow::MonitorResponse* response, std::function<void(::grpc::Status)>) = 0;
    };
    virtual class experimental_async_interface* experimental_async() { return nullptr; }
  private:
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ProfileResponse>* AsyncProfileRaw(::grpc::ClientContext* context, const ::tensorflow::ProfileRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ProfileResponse>* PrepareAsyncProfileRaw(::grpc::ClientContext* context, const ::tensorflow::ProfileRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::TerminateResponse>* AsyncTerminateRaw(::grpc::ClientContext* context, const ::tensorflow::TerminateRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::TerminateResponse>* PrepareAsyncTerminateRaw(::grpc::ClientContext* context, const ::tensorflow::TerminateRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::MonitorResponse>* AsyncMonitorRaw(::grpc::ClientContext* context, const ::tensorflow::MonitorRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::MonitorResponse>* PrepareAsyncMonitorRaw(::grpc::ClientContext* context, const ::tensorflow::MonitorRequest& request, ::grpc::CompletionQueue* cq) = 0;
  };
  class Stub final : public StubInterface {
   public:
    Stub(const std::shared_ptr< ::grpc::ChannelInterface>& channel);
    ::grpc::Status Profile(::grpc::ClientContext* context, const ::tensorflow::ProfileRequest& request, ::tensorflow::ProfileResponse* response) override;
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::ProfileResponse>> AsyncProfile(::grpc::ClientContext* context, const ::tensorflow::ProfileRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::ProfileResponse>>(AsyncProfileRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::ProfileResponse>> PrepareAsyncProfile(::grpc::ClientContext* context, const ::tensorflow::ProfileRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::ProfileResponse>>(PrepareAsyncProfileRaw(context, request, cq));
    }
    ::grpc::Status Terminate(::grpc::ClientContext* context, const ::tensorflow::TerminateRequest& request, ::tensorflow::TerminateResponse* response) override;
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::TerminateResponse>> AsyncTerminate(::grpc::ClientContext* context, const ::tensorflow::TerminateRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::TerminateResponse>>(AsyncTerminateRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::TerminateResponse>> PrepareAsyncTerminate(::grpc::ClientContext* context, const ::tensorflow::TerminateRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::TerminateResponse>>(PrepareAsyncTerminateRaw(context, request, cq));
    }
    ::grpc::Status Monitor(::grpc::ClientContext* context, const ::tensorflow::MonitorRequest& request, ::tensorflow::MonitorResponse* response) override;
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::MonitorResponse>> AsyncMonitor(::grpc::ClientContext* context, const ::tensorflow::MonitorRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::MonitorResponse>>(AsyncMonitorRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::MonitorResponse>> PrepareAsyncMonitor(::grpc::ClientContext* context, const ::tensorflow::MonitorRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::MonitorResponse>>(PrepareAsyncMonitorRaw(context, request, cq));
    }
    class experimental_async final :
      public StubInterface::experimental_async_interface {
     public:
      void Profile(::grpc::ClientContext* context, const ::tensorflow::ProfileRequest* request, ::tensorflow::ProfileResponse* response, std::function<void(::grpc::Status)>) override;
      void Terminate(::grpc::ClientContext* context, const ::tensorflow::TerminateRequest* request, ::tensorflow::TerminateResponse* response, std::function<void(::grpc::Status)>) override;
      void Monitor(::grpc::ClientContext* context, const ::tensorflow::MonitorRequest* request, ::tensorflow::MonitorResponse* response, std::function<void(::grpc::Status)>) override;
     private:
      friend class Stub;
      explicit experimental_async(Stub* stub): stub_(stub) { }
      Stub* stub() { return stub_; }
      Stub* stub_;
    };
    class experimental_async_interface* experimental_async() override { return &async_stub_; }

   private:
    std::shared_ptr< ::grpc::ChannelInterface> channel_;
    class experimental_async async_stub_{this};
    ::grpc::ClientAsyncResponseReader< ::tensorflow::ProfileResponse>* AsyncProfileRaw(::grpc::ClientContext* context, const ::tensorflow::ProfileRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::ProfileResponse>* PrepareAsyncProfileRaw(::grpc::ClientContext* context, const ::tensorflow::ProfileRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::TerminateResponse>* AsyncTerminateRaw(::grpc::ClientContext* context, const ::tensorflow::TerminateRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::TerminateResponse>* PrepareAsyncTerminateRaw(::grpc::ClientContext* context, const ::tensorflow::TerminateRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::MonitorResponse>* AsyncMonitorRaw(::grpc::ClientContext* context, const ::tensorflow::MonitorRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::MonitorResponse>* PrepareAsyncMonitorRaw(::grpc::ClientContext* context, const ::tensorflow::MonitorRequest& request, ::grpc::CompletionQueue* cq) override;
    const ::grpc::internal::RpcMethod rpcmethod_Profile_;
    const ::grpc::internal::RpcMethod rpcmethod_Terminate_;
    const ::grpc::internal::RpcMethod rpcmethod_Monitor_;
  };
  static std::unique_ptr<Stub> NewStub(const std::shared_ptr< ::grpc::ChannelInterface>& channel, const ::grpc::StubOptions& options = ::grpc::StubOptions());

  class Service : public ::grpc::Service {
   public:
    Service();
    virtual ~Service();
    // Starts a profiling session, blocks until it completes, and returns data.
    virtual ::grpc::Status Profile(::grpc::ServerContext* context, const ::tensorflow::ProfileRequest* request, ::tensorflow::ProfileResponse* response);
    // Signal to terminate the Profile rpc for a on-going profiling session,
    // The Profile rpc will return successfully and prematurely without timeout.
    // This is used by programmatic mode to end the session in workers.
    virtual ::grpc::Status Terminate(::grpc::ServerContext* context, const ::tensorflow::TerminateRequest* request, ::tensorflow::TerminateResponse* response);
    // Collects profiling data and returns user-friendly metrics.
    virtual ::grpc::Status Monitor(::grpc::ServerContext* context, const ::tensorflow::MonitorRequest* request, ::tensorflow::MonitorResponse* response);
  };
  template <class BaseClass>
  class WithAsyncMethod_Profile : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithAsyncMethod_Profile() {
      ::grpc::Service::MarkMethodAsync(0);
    }
    ~WithAsyncMethod_Profile() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status Profile(::grpc::ServerContext* context, const ::tensorflow::ProfileRequest* request, ::tensorflow::ProfileResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestProfile(::grpc::ServerContext* context, ::tensorflow::ProfileRequest* request, ::grpc::ServerAsyncResponseWriter< ::tensorflow::ProfileResponse>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(0, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithAsyncMethod_Terminate : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithAsyncMethod_Terminate() {
      ::grpc::Service::MarkMethodAsync(1);
    }
    ~WithAsyncMethod_Terminate() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status Terminate(::grpc::ServerContext* context, const ::tensorflow::TerminateRequest* request, ::tensorflow::TerminateResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestTerminate(::grpc::ServerContext* context, ::tensorflow::TerminateRequest* request, ::grpc::ServerAsyncResponseWriter< ::tensorflow::TerminateResponse>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(1, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithAsyncMethod_Monitor : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithAsyncMethod_Monitor() {
      ::grpc::Service::MarkMethodAsync(2);
    }
    ~WithAsyncMethod_Monitor() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status Monitor(::grpc::ServerContext* context, const ::tensorflow::MonitorRequest* request, ::tensorflow::MonitorResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestMonitor(::grpc::ServerContext* context, ::tensorflow::MonitorRequest* request, ::grpc::ServerAsyncResponseWriter< ::tensorflow::MonitorResponse>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(2, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  typedef WithAsyncMethod_Profile<WithAsyncMethod_Terminate<WithAsyncMethod_Monitor<Service > > > AsyncService;
  template <class BaseClass>
  class WithGenericMethod_Profile : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithGenericMethod_Profile() {
      ::grpc::Service::MarkMethodGeneric(0);
    }
    ~WithGenericMethod_Profile() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status Profile(::grpc::ServerContext* context, const ::tensorflow::ProfileRequest* request, ::tensorflow::ProfileResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
  };
  template <class BaseClass>
  class WithGenericMethod_Terminate : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithGenericMethod_Terminate() {
      ::grpc::Service::MarkMethodGeneric(1);
    }
    ~WithGenericMethod_Terminate() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status Terminate(::grpc::ServerContext* context, const ::tensorflow::TerminateRequest* request, ::tensorflow::TerminateResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
  };
  template <class BaseClass>
  class WithGenericMethod_Monitor : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithGenericMethod_Monitor() {
      ::grpc::Service::MarkMethodGeneric(2);
    }
    ~WithGenericMethod_Monitor() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status Monitor(::grpc::ServerContext* context, const ::tensorflow::MonitorRequest* request, ::tensorflow::MonitorResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
  };
  template <class BaseClass>
  class WithRawMethod_Profile : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithRawMethod_Profile() {
      ::grpc::Service::MarkMethodRaw(0);
    }
    ~WithRawMethod_Profile() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status Profile(::grpc::ServerContext* context, const ::tensorflow::ProfileRequest* request, ::tensorflow::ProfileResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestProfile(::grpc::ServerContext* context, ::grpc::ByteBuffer* request, ::grpc::ServerAsyncResponseWriter< ::grpc::ByteBuffer>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(0, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithRawMethod_Terminate : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithRawMethod_Terminate() {
      ::grpc::Service::MarkMethodRaw(1);
    }
    ~WithRawMethod_Terminate() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status Terminate(::grpc::ServerContext* context, const ::tensorflow::TerminateRequest* request, ::tensorflow::TerminateResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestTerminate(::grpc::ServerContext* context, ::grpc::ByteBuffer* request, ::grpc::ServerAsyncResponseWriter< ::grpc::ByteBuffer>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(1, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithRawMethod_Monitor : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithRawMethod_Monitor() {
      ::grpc::Service::MarkMethodRaw(2);
    }
    ~WithRawMethod_Monitor() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status Monitor(::grpc::ServerContext* context, const ::tensorflow::MonitorRequest* request, ::tensorflow::MonitorResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestMonitor(::grpc::ServerContext* context, ::grpc::ByteBuffer* request, ::grpc::ServerAsyncResponseWriter< ::grpc::ByteBuffer>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(2, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithStreamedUnaryMethod_Profile : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithStreamedUnaryMethod_Profile() {
      ::grpc::Service::MarkMethodStreamed(0,
        new ::grpc::internal::StreamedUnaryHandler< ::tensorflow::ProfileRequest, ::tensorflow::ProfileResponse>(std::bind(&WithStreamedUnaryMethod_Profile<BaseClass>::StreamedProfile, this, std::placeholders::_1, std::placeholders::_2)));
    }
    ~WithStreamedUnaryMethod_Profile() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable regular version of this method
    ::grpc::Status Profile(::grpc::ServerContext* context, const ::tensorflow::ProfileRequest* request, ::tensorflow::ProfileResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    // replace default version of method with streamed unary
    virtual ::grpc::Status StreamedProfile(::grpc::ServerContext* context, ::grpc::ServerUnaryStreamer< ::tensorflow::ProfileRequest,::tensorflow::ProfileResponse>* server_unary_streamer) = 0;
  };
  template <class BaseClass>
  class WithStreamedUnaryMethod_Terminate : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithStreamedUnaryMethod_Terminate() {
      ::grpc::Service::MarkMethodStreamed(1,
        new ::grpc::internal::StreamedUnaryHandler< ::tensorflow::TerminateRequest, ::tensorflow::TerminateResponse>(std::bind(&WithStreamedUnaryMethod_Terminate<BaseClass>::StreamedTerminate, this, std::placeholders::_1, std::placeholders::_2)));
    }
    ~WithStreamedUnaryMethod_Terminate() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable regular version of this method
    ::grpc::Status Terminate(::grpc::ServerContext* context, const ::tensorflow::TerminateRequest* request, ::tensorflow::TerminateResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    // replace default version of method with streamed unary
    virtual ::grpc::Status StreamedTerminate(::grpc::ServerContext* context, ::grpc::ServerUnaryStreamer< ::tensorflow::TerminateRequest,::tensorflow::TerminateResponse>* server_unary_streamer) = 0;
  };
  template <class BaseClass>
  class WithStreamedUnaryMethod_Monitor : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithStreamedUnaryMethod_Monitor() {
      ::grpc::Service::MarkMethodStreamed(2,
        new ::grpc::internal::StreamedUnaryHandler< ::tensorflow::MonitorRequest, ::tensorflow::MonitorResponse>(std::bind(&WithStreamedUnaryMethod_Monitor<BaseClass>::StreamedMonitor, this, std::placeholders::_1, std::placeholders::_2)));
    }
    ~WithStreamedUnaryMethod_Monitor() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable regular version of this method
    ::grpc::Status Monitor(::grpc::ServerContext* context, const ::tensorflow::MonitorRequest* request, ::tensorflow::MonitorResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    // replace default version of method with streamed unary
    virtual ::grpc::Status StreamedMonitor(::grpc::ServerContext* context, ::grpc::ServerUnaryStreamer< ::tensorflow::MonitorRequest,::tensorflow::MonitorResponse>* server_unary_streamer) = 0;
  };
  typedef WithStreamedUnaryMethod_Profile<WithStreamedUnaryMethod_Terminate<WithStreamedUnaryMethod_Monitor<Service > > > StreamedUnaryService;
  typedef Service SplitStreamedService;
  typedef WithStreamedUnaryMethod_Profile<WithStreamedUnaryMethod_Terminate<WithStreamedUnaryMethod_Monitor<Service > > > StreamedService;
};

}  // namespace tensorflow


#endif  // GRPC_tensorflow_2fcore_2fprofiler_2fprofiler_5fservice_2eproto__INCLUDED
