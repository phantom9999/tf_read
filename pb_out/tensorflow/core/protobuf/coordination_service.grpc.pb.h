// Generated by the gRPC C++ plugin.
// If you make any local change, they will be lost.
// source: tensorflow/core/protobuf/coordination_service.proto
#ifndef GRPC_tensorflow_2fcore_2fprotobuf_2fcoordination_5fservice_2eproto__INCLUDED
#define GRPC_tensorflow_2fcore_2fprotobuf_2fcoordination_5fservice_2eproto__INCLUDED

#include "tensorflow/core/protobuf/coordination_service.pb.h"

#include <functional>
#include <grpcpp/impl/codegen/async_generic_service.h>
#include <grpcpp/impl/codegen/async_stream.h>
#include <grpcpp/impl/codegen/async_unary_call.h>
#include <grpcpp/impl/codegen/method_handler_impl.h>
#include <grpcpp/impl/codegen/proto_utils.h>
#include <grpcpp/impl/codegen/rpc_method.h>
#include <grpcpp/impl/codegen/service_type.h>
#include <grpcpp/impl/codegen/status.h>
#include <grpcpp/impl/codegen/stub_options.h>
#include <grpcpp/impl/codegen/sync_stream.h>

namespace grpc {
class CompletionQueue;
class Channel;
class ServerCompletionQueue;
class ServerContext;
}  // namespace grpc

namespace tensorflow {

// Coordination Service defines a TensorFlow service that controls and
// coordinates distributed execution in a cluster of multiple tasks.
//
// The service keeps track of the cluster configuration and the state of cluster
// members or the leader depending on the role of the current task. The
// distributed runtime leverages this service to coordinate and perform cluster
// initialization, check the healthiness of tasks, and propagate error
// messages to the cluster.
class CoordinationService final {
 public:
  static constexpr char const* service_full_name() {
    return "tensorflow.CoordinationService";
  }
  class StubInterface {
   public:
    virtual ~StubInterface() {}
    // Register task to coordination service so that the service starts to track
    // liveness of the task. RPC blocks and returns only when it registers to
    // the service successfully, or error happens in the registering process.
    virtual ::grpc::Status RegisterTask(::grpc::ClientContext* context, const ::tensorflow::RegisterTaskRequest& request, ::tensorflow::RegisterTaskResponse* response) = 0;
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::RegisterTaskResponse>> AsyncRegisterTask(::grpc::ClientContext* context, const ::tensorflow::RegisterTaskRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::RegisterTaskResponse>>(AsyncRegisterTaskRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::RegisterTaskResponse>> PrepareAsyncRegisterTask(::grpc::ClientContext* context, const ::tensorflow::RegisterTaskRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::RegisterTaskResponse>>(PrepareAsyncRegisterTaskRaw(context, request, cq));
    }
    // Heartbeat message from task to coordination service. Heartbeat is sent from
    // a task to refresh its timestamp on leader to avoid it becoming stale.
    // RPC responds immediately after refreshing the timestamp on leader.
    virtual ::grpc::Status Heartbeat(::grpc::ClientContext* context, const ::tensorflow::HeartbeatRequest& request, ::tensorflow::HeartbeatResponse* response) = 0;
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::HeartbeatResponse>> AsyncHeartbeat(::grpc::ClientContext* context, const ::tensorflow::HeartbeatRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::HeartbeatResponse>>(AsyncHeartbeatRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::HeartbeatResponse>> PrepareAsyncHeartbeat(::grpc::ClientContext* context, const ::tensorflow::HeartbeatRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::HeartbeatResponse>>(PrepareAsyncHeartbeatRaw(context, request, cq));
    }
    // Wait for all tasks in the cluster to be up and running. The RPC request
    // only gets responded when all tasks have registered, or some error occurs.
    virtual ::grpc::Status WaitForAllTasks(::grpc::ClientContext* context, const ::tensorflow::WaitForAllTasksRequest& request, ::tensorflow::WaitForAllTasksResponse* response) = 0;
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::WaitForAllTasksResponse>> AsyncWaitForAllTasks(::grpc::ClientContext* context, const ::tensorflow::WaitForAllTasksRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::WaitForAllTasksResponse>>(AsyncWaitForAllTasksRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::WaitForAllTasksResponse>> PrepareAsyncWaitForAllTasks(::grpc::ClientContext* context, const ::tensorflow::WaitForAllTasksRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::WaitForAllTasksResponse>>(PrepareAsyncWaitForAllTasksRaw(context, request, cq));
    }
    // Disconnects task from the service. If `shutdown_barrier_timeout_in_ms` is
    // specified in the config, blocks until all tasks reach the barrier before
    // disconnecting together. If the barrier times out, tasks at the barrier will
    // still disconnect, while an error is reported to tasks that did not reach
    // the barrier on time.
    virtual ::grpc::Status ShutdownTask(::grpc::ClientContext* context, const ::tensorflow::ShutdownTaskRequest& request, ::tensorflow::ShutdownTaskResponse* response) = 0;
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ShutdownTaskResponse>> AsyncShutdownTask(::grpc::ClientContext* context, const ::tensorflow::ShutdownTaskRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ShutdownTaskResponse>>(AsyncShutdownTaskRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ShutdownTaskResponse>> PrepareAsyncShutdownTask(::grpc::ClientContext* context, const ::tensorflow::ShutdownTaskRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ShutdownTaskResponse>>(PrepareAsyncShutdownTaskRaw(context, request, cq));
    }
    // Disconnects task from the service if it is in an ERROR state, thereby
    // allowing it to reconnect via RegisterTask() in the future.
    virtual ::grpc::Status ResetTask(::grpc::ClientContext* context, const ::tensorflow::ResetTaskRequest& request, ::tensorflow::ResetTaskResponse* response) = 0;
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ResetTaskResponse>> AsyncResetTask(::grpc::ClientContext* context, const ::tensorflow::ResetTaskRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ResetTaskResponse>>(AsyncResetTaskRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ResetTaskResponse>> PrepareAsyncResetTask(::grpc::ClientContext* context, const ::tensorflow::ResetTaskRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ResetTaskResponse>>(PrepareAsyncResetTaskRaw(context, request, cq));
    }
    // Report error to the task. RPC sets the receiving instance of coordination
    // service agent to error state permanently.
    // TODO(b/195990880): Consider splitting this into a different RPC service.
    virtual ::grpc::Status ReportErrorToTask(::grpc::ClientContext* context, const ::tensorflow::ReportErrorToTaskRequest& request, ::tensorflow::ReportErrorToTaskResponse* response) = 0;
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ReportErrorToTaskResponse>> AsyncReportErrorToTask(::grpc::ClientContext* context, const ::tensorflow::ReportErrorToTaskRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ReportErrorToTaskResponse>>(AsyncReportErrorToTaskRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ReportErrorToTaskResponse>> PrepareAsyncReportErrorToTask(::grpc::ClientContext* context, const ::tensorflow::ReportErrorToTaskRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ReportErrorToTaskResponse>>(PrepareAsyncReportErrorToTaskRaw(context, request, cq));
    }
    // Report task error to coordination service. RPC sets the service-side task
    // state to error, and propagate the error to other tasks in the cluster.
    virtual ::grpc::Status ReportErrorToService(::grpc::ClientContext* context, const ::tensorflow::ReportErrorToServiceRequest& request, ::tensorflow::ReportErrorToServiceResponse* response) = 0;
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ReportErrorToServiceResponse>> AsyncReportErrorToService(::grpc::ClientContext* context, const ::tensorflow::ReportErrorToServiceRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ReportErrorToServiceResponse>>(AsyncReportErrorToServiceRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ReportErrorToServiceResponse>> PrepareAsyncReportErrorToService(::grpc::ClientContext* context, const ::tensorflow::ReportErrorToServiceRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ReportErrorToServiceResponse>>(PrepareAsyncReportErrorToServiceRaw(context, request, cq));
    }
    // Insert configuration key-value that will be accessible to all cluster
    // tasks. The key can be formatted as Unix file path with hierarchy. The
    // coordination service key-value store should only be used for cluster
    // configuration data.
    virtual ::grpc::Status InsertKeyValue(::grpc::ClientContext* context, const ::tensorflow::InsertKeyValueRequest& request, ::tensorflow::InsertKeyValueResponse* response) = 0;
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::InsertKeyValueResponse>> AsyncInsertKeyValue(::grpc::ClientContext* context, const ::tensorflow::InsertKeyValueRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::InsertKeyValueResponse>>(AsyncInsertKeyValueRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::InsertKeyValueResponse>> PrepareAsyncInsertKeyValue(::grpc::ClientContext* context, const ::tensorflow::InsertKeyValueRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::InsertKeyValueResponse>>(PrepareAsyncInsertKeyValueRaw(context, request, cq));
    }
    // Get configuration key-value. The request blocks until the key-value data
    // becomes available (i.e., set by a task in the cluster).
    virtual ::grpc::Status GetKeyValue(::grpc::ClientContext* context, const ::tensorflow::GetKeyValueRequest& request, ::tensorflow::GetKeyValueResponse* response) = 0;
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::GetKeyValueResponse>> AsyncGetKeyValue(::grpc::ClientContext* context, const ::tensorflow::GetKeyValueRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::GetKeyValueResponse>>(AsyncGetKeyValueRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::GetKeyValueResponse>> PrepareAsyncGetKeyValue(::grpc::ClientContext* context, const ::tensorflow::GetKeyValueRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::GetKeyValueResponse>>(PrepareAsyncGetKeyValueRaw(context, request, cq));
    }
    // Delete configuration key-value. If is_directory is set in request,
    // recursively clean up all key-values under the path specified by `key`.
    virtual ::grpc::Status DeleteKeyValue(::grpc::ClientContext* context, const ::tensorflow::DeleteKeyValueRequest& request, ::tensorflow::DeleteKeyValueResponse* response) = 0;
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::DeleteKeyValueResponse>> AsyncDeleteKeyValue(::grpc::ClientContext* context, const ::tensorflow::DeleteKeyValueRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::DeleteKeyValueResponse>>(AsyncDeleteKeyValueRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::DeleteKeyValueResponse>> PrepareAsyncDeleteKeyValue(::grpc::ClientContext* context, const ::tensorflow::DeleteKeyValueRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::DeleteKeyValueResponse>>(PrepareAsyncDeleteKeyValueRaw(context, request, cq));
    }
    // Blocks until all (or a subset of) tasks are at the barrier or the barrier
    // fails.
    //
    // `barrier_id` should be unique across barriers. Once the barrier has passed
    // or failed, subsequent calls will not block, and immediately respond with
    // the previous response.
    //
    // The first WaitAtBarrier() call received by the service for a particular
    // barrier id is special in that it determines the barrier deadline based on
    // timeout duration.
    // However, if subsequent calls by different agents specify a different set of
    // `tasks` for the same `barrier_id`, the barrier will fail instantly.
    //
    // If no tasks are specified (default), the barrier will block for all the
    // connected tasks.
    //
    // Possible service errors:
    //   - DeadlineExceeded: Timed out waiting for specified tasks at the barrier.
    //      Deadline is determined by the server timestamp when it receives the
    //      first WaitAtBarrier() + timeout duration.
    //   - Cancelled: One of the tasks called CancelBarrier().
    //   - Aborted: Service is shutting down.
    //   - Internal: Any participating task is in ERROR state.
    //   - InvalidArgument: (1) Conflicting tasks specified by different agents
    //       for the same barrier, (2) one of the participating tasks is not in
    //       the cluster, or (3) task making the request is not included in the
    //       list of participating tasks.
    virtual ::grpc::Status Barrier(::grpc::ClientContext* context, const ::tensorflow::BarrierRequest& request, ::tensorflow::BarrierResponse* response) = 0;
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::BarrierResponse>> AsyncBarrier(::grpc::ClientContext* context, const ::tensorflow::BarrierRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::BarrierResponse>>(AsyncBarrierRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::BarrierResponse>> PrepareAsyncBarrier(::grpc::ClientContext* context, const ::tensorflow::BarrierRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::BarrierResponse>>(PrepareAsyncBarrierRaw(context, request, cq));
    }
    // Aborts the barrier if it is ongoing.
    // Current and future WaitAtBarrier() calls with the same id will return a
    // CANCELLED error status.
    // Possible service errors:
    //   - FailedPrecondition: Barrier has already been passed.
    //   - NotFound: No barrier with the specified id is found.
    virtual ::grpc::Status CancelBarrier(::grpc::ClientContext* context, const ::tensorflow::CancelBarrierRequest& request, ::tensorflow::CancelBarrierResponse* response) = 0;
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::CancelBarrierResponse>> AsyncCancelBarrier(::grpc::ClientContext* context, const ::tensorflow::CancelBarrierRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::CancelBarrierResponse>>(AsyncCancelBarrierRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::CancelBarrierResponse>> PrepareAsyncCancelBarrier(::grpc::ClientContext* context, const ::tensorflow::CancelBarrierRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::CancelBarrierResponse>>(PrepareAsyncCancelBarrierRaw(context, request, cq));
    }
    class experimental_async_interface {
     public:
      virtual ~experimental_async_interface() {}
      // Register task to coordination service so that the service starts to track
      // liveness of the task. RPC blocks and returns only when it registers to
      // the service successfully, or error happens in the registering process.
      virtual void RegisterTask(::grpc::ClientContext* context, const ::tensorflow::RegisterTaskRequest* request, ::tensorflow::RegisterTaskResponse* response, std::function<void(::grpc::Status)>) = 0;
      // Heartbeat message from task to coordination service. Heartbeat is sent from
      // a task to refresh its timestamp on leader to avoid it becoming stale.
      // RPC responds immediately after refreshing the timestamp on leader.
      virtual void Heartbeat(::grpc::ClientContext* context, const ::tensorflow::HeartbeatRequest* request, ::tensorflow::HeartbeatResponse* response, std::function<void(::grpc::Status)>) = 0;
      // Wait for all tasks in the cluster to be up and running. The RPC request
      // only gets responded when all tasks have registered, or some error occurs.
      virtual void WaitForAllTasks(::grpc::ClientContext* context, const ::tensorflow::WaitForAllTasksRequest* request, ::tensorflow::WaitForAllTasksResponse* response, std::function<void(::grpc::Status)>) = 0;
      // Disconnects task from the service. If `shutdown_barrier_timeout_in_ms` is
      // specified in the config, blocks until all tasks reach the barrier before
      // disconnecting together. If the barrier times out, tasks at the barrier will
      // still disconnect, while an error is reported to tasks that did not reach
      // the barrier on time.
      virtual void ShutdownTask(::grpc::ClientContext* context, const ::tensorflow::ShutdownTaskRequest* request, ::tensorflow::ShutdownTaskResponse* response, std::function<void(::grpc::Status)>) = 0;
      // Disconnects task from the service if it is in an ERROR state, thereby
      // allowing it to reconnect via RegisterTask() in the future.
      virtual void ResetTask(::grpc::ClientContext* context, const ::tensorflow::ResetTaskRequest* request, ::tensorflow::ResetTaskResponse* response, std::function<void(::grpc::Status)>) = 0;
      // Report error to the task. RPC sets the receiving instance of coordination
      // service agent to error state permanently.
      // TODO(b/195990880): Consider splitting this into a different RPC service.
      virtual void ReportErrorToTask(::grpc::ClientContext* context, const ::tensorflow::ReportErrorToTaskRequest* request, ::tensorflow::ReportErrorToTaskResponse* response, std::function<void(::grpc::Status)>) = 0;
      // Report task error to coordination service. RPC sets the service-side task
      // state to error, and propagate the error to other tasks in the cluster.
      virtual void ReportErrorToService(::grpc::ClientContext* context, const ::tensorflow::ReportErrorToServiceRequest* request, ::tensorflow::ReportErrorToServiceResponse* response, std::function<void(::grpc::Status)>) = 0;
      // Insert configuration key-value that will be accessible to all cluster
      // tasks. The key can be formatted as Unix file path with hierarchy. The
      // coordination service key-value store should only be used for cluster
      // configuration data.
      virtual void InsertKeyValue(::grpc::ClientContext* context, const ::tensorflow::InsertKeyValueRequest* request, ::tensorflow::InsertKeyValueResponse* response, std::function<void(::grpc::Status)>) = 0;
      // Get configuration key-value. The request blocks until the key-value data
      // becomes available (i.e., set by a task in the cluster).
      virtual void GetKeyValue(::grpc::ClientContext* context, const ::tensorflow::GetKeyValueRequest* request, ::tensorflow::GetKeyValueResponse* response, std::function<void(::grpc::Status)>) = 0;
      // Delete configuration key-value. If is_directory is set in request,
      // recursively clean up all key-values under the path specified by `key`.
      virtual void DeleteKeyValue(::grpc::ClientContext* context, const ::tensorflow::DeleteKeyValueRequest* request, ::tensorflow::DeleteKeyValueResponse* response, std::function<void(::grpc::Status)>) = 0;
      // Blocks until all (or a subset of) tasks are at the barrier or the barrier
      // fails.
      //
      // `barrier_id` should be unique across barriers. Once the barrier has passed
      // or failed, subsequent calls will not block, and immediately respond with
      // the previous response.
      //
      // The first WaitAtBarrier() call received by the service for a particular
      // barrier id is special in that it determines the barrier deadline based on
      // timeout duration.
      // However, if subsequent calls by different agents specify a different set of
      // `tasks` for the same `barrier_id`, the barrier will fail instantly.
      //
      // If no tasks are specified (default), the barrier will block for all the
      // connected tasks.
      //
      // Possible service errors:
      //   - DeadlineExceeded: Timed out waiting for specified tasks at the barrier.
      //      Deadline is determined by the server timestamp when it receives the
      //      first WaitAtBarrier() + timeout duration.
      //   - Cancelled: One of the tasks called CancelBarrier().
      //   - Aborted: Service is shutting down.
      //   - Internal: Any participating task is in ERROR state.
      //   - InvalidArgument: (1) Conflicting tasks specified by different agents
      //       for the same barrier, (2) one of the participating tasks is not in
      //       the cluster, or (3) task making the request is not included in the
      //       list of participating tasks.
      virtual void Barrier(::grpc::ClientContext* context, const ::tensorflow::BarrierRequest* request, ::tensorflow::BarrierResponse* response, std::function<void(::grpc::Status)>) = 0;
      // Aborts the barrier if it is ongoing.
      // Current and future WaitAtBarrier() calls with the same id will return a
      // CANCELLED error status.
      // Possible service errors:
      //   - FailedPrecondition: Barrier has already been passed.
      //   - NotFound: No barrier with the specified id is found.
      virtual void CancelBarrier(::grpc::ClientContext* context, const ::tensorflow::CancelBarrierRequest* request, ::tensorflow::CancelBarrierResponse* response, std::function<void(::grpc::Status)>) = 0;
    };
    virtual class experimental_async_interface* experimental_async() { return nullptr; }
  private:
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::RegisterTaskResponse>* AsyncRegisterTaskRaw(::grpc::ClientContext* context, const ::tensorflow::RegisterTaskRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::RegisterTaskResponse>* PrepareAsyncRegisterTaskRaw(::grpc::ClientContext* context, const ::tensorflow::RegisterTaskRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::HeartbeatResponse>* AsyncHeartbeatRaw(::grpc::ClientContext* context, const ::tensorflow::HeartbeatRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::HeartbeatResponse>* PrepareAsyncHeartbeatRaw(::grpc::ClientContext* context, const ::tensorflow::HeartbeatRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::WaitForAllTasksResponse>* AsyncWaitForAllTasksRaw(::grpc::ClientContext* context, const ::tensorflow::WaitForAllTasksRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::WaitForAllTasksResponse>* PrepareAsyncWaitForAllTasksRaw(::grpc::ClientContext* context, const ::tensorflow::WaitForAllTasksRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ShutdownTaskResponse>* AsyncShutdownTaskRaw(::grpc::ClientContext* context, const ::tensorflow::ShutdownTaskRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ShutdownTaskResponse>* PrepareAsyncShutdownTaskRaw(::grpc::ClientContext* context, const ::tensorflow::ShutdownTaskRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ResetTaskResponse>* AsyncResetTaskRaw(::grpc::ClientContext* context, const ::tensorflow::ResetTaskRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ResetTaskResponse>* PrepareAsyncResetTaskRaw(::grpc::ClientContext* context, const ::tensorflow::ResetTaskRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ReportErrorToTaskResponse>* AsyncReportErrorToTaskRaw(::grpc::ClientContext* context, const ::tensorflow::ReportErrorToTaskRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ReportErrorToTaskResponse>* PrepareAsyncReportErrorToTaskRaw(::grpc::ClientContext* context, const ::tensorflow::ReportErrorToTaskRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ReportErrorToServiceResponse>* AsyncReportErrorToServiceRaw(::grpc::ClientContext* context, const ::tensorflow::ReportErrorToServiceRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::ReportErrorToServiceResponse>* PrepareAsyncReportErrorToServiceRaw(::grpc::ClientContext* context, const ::tensorflow::ReportErrorToServiceRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::InsertKeyValueResponse>* AsyncInsertKeyValueRaw(::grpc::ClientContext* context, const ::tensorflow::InsertKeyValueRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::InsertKeyValueResponse>* PrepareAsyncInsertKeyValueRaw(::grpc::ClientContext* context, const ::tensorflow::InsertKeyValueRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::GetKeyValueResponse>* AsyncGetKeyValueRaw(::grpc::ClientContext* context, const ::tensorflow::GetKeyValueRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::GetKeyValueResponse>* PrepareAsyncGetKeyValueRaw(::grpc::ClientContext* context, const ::tensorflow::GetKeyValueRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::DeleteKeyValueResponse>* AsyncDeleteKeyValueRaw(::grpc::ClientContext* context, const ::tensorflow::DeleteKeyValueRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::DeleteKeyValueResponse>* PrepareAsyncDeleteKeyValueRaw(::grpc::ClientContext* context, const ::tensorflow::DeleteKeyValueRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::BarrierResponse>* AsyncBarrierRaw(::grpc::ClientContext* context, const ::tensorflow::BarrierRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::BarrierResponse>* PrepareAsyncBarrierRaw(::grpc::ClientContext* context, const ::tensorflow::BarrierRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::CancelBarrierResponse>* AsyncCancelBarrierRaw(::grpc::ClientContext* context, const ::tensorflow::CancelBarrierRequest& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::tensorflow::CancelBarrierResponse>* PrepareAsyncCancelBarrierRaw(::grpc::ClientContext* context, const ::tensorflow::CancelBarrierRequest& request, ::grpc::CompletionQueue* cq) = 0;
  };
  class Stub final : public StubInterface {
   public:
    Stub(const std::shared_ptr< ::grpc::ChannelInterface>& channel);
    ::grpc::Status RegisterTask(::grpc::ClientContext* context, const ::tensorflow::RegisterTaskRequest& request, ::tensorflow::RegisterTaskResponse* response) override;
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::RegisterTaskResponse>> AsyncRegisterTask(::grpc::ClientContext* context, const ::tensorflow::RegisterTaskRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::RegisterTaskResponse>>(AsyncRegisterTaskRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::RegisterTaskResponse>> PrepareAsyncRegisterTask(::grpc::ClientContext* context, const ::tensorflow::RegisterTaskRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::RegisterTaskResponse>>(PrepareAsyncRegisterTaskRaw(context, request, cq));
    }
    ::grpc::Status Heartbeat(::grpc::ClientContext* context, const ::tensorflow::HeartbeatRequest& request, ::tensorflow::HeartbeatResponse* response) override;
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::HeartbeatResponse>> AsyncHeartbeat(::grpc::ClientContext* context, const ::tensorflow::HeartbeatRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::HeartbeatResponse>>(AsyncHeartbeatRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::HeartbeatResponse>> PrepareAsyncHeartbeat(::grpc::ClientContext* context, const ::tensorflow::HeartbeatRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::HeartbeatResponse>>(PrepareAsyncHeartbeatRaw(context, request, cq));
    }
    ::grpc::Status WaitForAllTasks(::grpc::ClientContext* context, const ::tensorflow::WaitForAllTasksRequest& request, ::tensorflow::WaitForAllTasksResponse* response) override;
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::WaitForAllTasksResponse>> AsyncWaitForAllTasks(::grpc::ClientContext* context, const ::tensorflow::WaitForAllTasksRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::WaitForAllTasksResponse>>(AsyncWaitForAllTasksRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::WaitForAllTasksResponse>> PrepareAsyncWaitForAllTasks(::grpc::ClientContext* context, const ::tensorflow::WaitForAllTasksRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::WaitForAllTasksResponse>>(PrepareAsyncWaitForAllTasksRaw(context, request, cq));
    }
    ::grpc::Status ShutdownTask(::grpc::ClientContext* context, const ::tensorflow::ShutdownTaskRequest& request, ::tensorflow::ShutdownTaskResponse* response) override;
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::ShutdownTaskResponse>> AsyncShutdownTask(::grpc::ClientContext* context, const ::tensorflow::ShutdownTaskRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::ShutdownTaskResponse>>(AsyncShutdownTaskRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::ShutdownTaskResponse>> PrepareAsyncShutdownTask(::grpc::ClientContext* context, const ::tensorflow::ShutdownTaskRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::ShutdownTaskResponse>>(PrepareAsyncShutdownTaskRaw(context, request, cq));
    }
    ::grpc::Status ResetTask(::grpc::ClientContext* context, const ::tensorflow::ResetTaskRequest& request, ::tensorflow::ResetTaskResponse* response) override;
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::ResetTaskResponse>> AsyncResetTask(::grpc::ClientContext* context, const ::tensorflow::ResetTaskRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::ResetTaskResponse>>(AsyncResetTaskRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::ResetTaskResponse>> PrepareAsyncResetTask(::grpc::ClientContext* context, const ::tensorflow::ResetTaskRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::ResetTaskResponse>>(PrepareAsyncResetTaskRaw(context, request, cq));
    }
    ::grpc::Status ReportErrorToTask(::grpc::ClientContext* context, const ::tensorflow::ReportErrorToTaskRequest& request, ::tensorflow::ReportErrorToTaskResponse* response) override;
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::ReportErrorToTaskResponse>> AsyncReportErrorToTask(::grpc::ClientContext* context, const ::tensorflow::ReportErrorToTaskRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::ReportErrorToTaskResponse>>(AsyncReportErrorToTaskRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::ReportErrorToTaskResponse>> PrepareAsyncReportErrorToTask(::grpc::ClientContext* context, const ::tensorflow::ReportErrorToTaskRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::ReportErrorToTaskResponse>>(PrepareAsyncReportErrorToTaskRaw(context, request, cq));
    }
    ::grpc::Status ReportErrorToService(::grpc::ClientContext* context, const ::tensorflow::ReportErrorToServiceRequest& request, ::tensorflow::ReportErrorToServiceResponse* response) override;
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::ReportErrorToServiceResponse>> AsyncReportErrorToService(::grpc::ClientContext* context, const ::tensorflow::ReportErrorToServiceRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::ReportErrorToServiceResponse>>(AsyncReportErrorToServiceRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::ReportErrorToServiceResponse>> PrepareAsyncReportErrorToService(::grpc::ClientContext* context, const ::tensorflow::ReportErrorToServiceRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::ReportErrorToServiceResponse>>(PrepareAsyncReportErrorToServiceRaw(context, request, cq));
    }
    ::grpc::Status InsertKeyValue(::grpc::ClientContext* context, const ::tensorflow::InsertKeyValueRequest& request, ::tensorflow::InsertKeyValueResponse* response) override;
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::InsertKeyValueResponse>> AsyncInsertKeyValue(::grpc::ClientContext* context, const ::tensorflow::InsertKeyValueRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::InsertKeyValueResponse>>(AsyncInsertKeyValueRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::InsertKeyValueResponse>> PrepareAsyncInsertKeyValue(::grpc::ClientContext* context, const ::tensorflow::InsertKeyValueRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::InsertKeyValueResponse>>(PrepareAsyncInsertKeyValueRaw(context, request, cq));
    }
    ::grpc::Status GetKeyValue(::grpc::ClientContext* context, const ::tensorflow::GetKeyValueRequest& request, ::tensorflow::GetKeyValueResponse* response) override;
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::GetKeyValueResponse>> AsyncGetKeyValue(::grpc::ClientContext* context, const ::tensorflow::GetKeyValueRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::GetKeyValueResponse>>(AsyncGetKeyValueRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::GetKeyValueResponse>> PrepareAsyncGetKeyValue(::grpc::ClientContext* context, const ::tensorflow::GetKeyValueRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::GetKeyValueResponse>>(PrepareAsyncGetKeyValueRaw(context, request, cq));
    }
    ::grpc::Status DeleteKeyValue(::grpc::ClientContext* context, const ::tensorflow::DeleteKeyValueRequest& request, ::tensorflow::DeleteKeyValueResponse* response) override;
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::DeleteKeyValueResponse>> AsyncDeleteKeyValue(::grpc::ClientContext* context, const ::tensorflow::DeleteKeyValueRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::DeleteKeyValueResponse>>(AsyncDeleteKeyValueRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::DeleteKeyValueResponse>> PrepareAsyncDeleteKeyValue(::grpc::ClientContext* context, const ::tensorflow::DeleteKeyValueRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::DeleteKeyValueResponse>>(PrepareAsyncDeleteKeyValueRaw(context, request, cq));
    }
    ::grpc::Status Barrier(::grpc::ClientContext* context, const ::tensorflow::BarrierRequest& request, ::tensorflow::BarrierResponse* response) override;
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::BarrierResponse>> AsyncBarrier(::grpc::ClientContext* context, const ::tensorflow::BarrierRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::BarrierResponse>>(AsyncBarrierRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::BarrierResponse>> PrepareAsyncBarrier(::grpc::ClientContext* context, const ::tensorflow::BarrierRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::BarrierResponse>>(PrepareAsyncBarrierRaw(context, request, cq));
    }
    ::grpc::Status CancelBarrier(::grpc::ClientContext* context, const ::tensorflow::CancelBarrierRequest& request, ::tensorflow::CancelBarrierResponse* response) override;
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::CancelBarrierResponse>> AsyncCancelBarrier(::grpc::ClientContext* context, const ::tensorflow::CancelBarrierRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::CancelBarrierResponse>>(AsyncCancelBarrierRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::CancelBarrierResponse>> PrepareAsyncCancelBarrier(::grpc::ClientContext* context, const ::tensorflow::CancelBarrierRequest& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::tensorflow::CancelBarrierResponse>>(PrepareAsyncCancelBarrierRaw(context, request, cq));
    }
    class experimental_async final :
      public StubInterface::experimental_async_interface {
     public:
      void RegisterTask(::grpc::ClientContext* context, const ::tensorflow::RegisterTaskRequest* request, ::tensorflow::RegisterTaskResponse* response, std::function<void(::grpc::Status)>) override;
      void Heartbeat(::grpc::ClientContext* context, const ::tensorflow::HeartbeatRequest* request, ::tensorflow::HeartbeatResponse* response, std::function<void(::grpc::Status)>) override;
      void WaitForAllTasks(::grpc::ClientContext* context, const ::tensorflow::WaitForAllTasksRequest* request, ::tensorflow::WaitForAllTasksResponse* response, std::function<void(::grpc::Status)>) override;
      void ShutdownTask(::grpc::ClientContext* context, const ::tensorflow::ShutdownTaskRequest* request, ::tensorflow::ShutdownTaskResponse* response, std::function<void(::grpc::Status)>) override;
      void ResetTask(::grpc::ClientContext* context, const ::tensorflow::ResetTaskRequest* request, ::tensorflow::ResetTaskResponse* response, std::function<void(::grpc::Status)>) override;
      void ReportErrorToTask(::grpc::ClientContext* context, const ::tensorflow::ReportErrorToTaskRequest* request, ::tensorflow::ReportErrorToTaskResponse* response, std::function<void(::grpc::Status)>) override;
      void ReportErrorToService(::grpc::ClientContext* context, const ::tensorflow::ReportErrorToServiceRequest* request, ::tensorflow::ReportErrorToServiceResponse* response, std::function<void(::grpc::Status)>) override;
      void InsertKeyValue(::grpc::ClientContext* context, const ::tensorflow::InsertKeyValueRequest* request, ::tensorflow::InsertKeyValueResponse* response, std::function<void(::grpc::Status)>) override;
      void GetKeyValue(::grpc::ClientContext* context, const ::tensorflow::GetKeyValueRequest* request, ::tensorflow::GetKeyValueResponse* response, std::function<void(::grpc::Status)>) override;
      void DeleteKeyValue(::grpc::ClientContext* context, const ::tensorflow::DeleteKeyValueRequest* request, ::tensorflow::DeleteKeyValueResponse* response, std::function<void(::grpc::Status)>) override;
      void Barrier(::grpc::ClientContext* context, const ::tensorflow::BarrierRequest* request, ::tensorflow::BarrierResponse* response, std::function<void(::grpc::Status)>) override;
      void CancelBarrier(::grpc::ClientContext* context, const ::tensorflow::CancelBarrierRequest* request, ::tensorflow::CancelBarrierResponse* response, std::function<void(::grpc::Status)>) override;
     private:
      friend class Stub;
      explicit experimental_async(Stub* stub): stub_(stub) { }
      Stub* stub() { return stub_; }
      Stub* stub_;
    };
    class experimental_async_interface* experimental_async() override { return &async_stub_; }

   private:
    std::shared_ptr< ::grpc::ChannelInterface> channel_;
    class experimental_async async_stub_{this};
    ::grpc::ClientAsyncResponseReader< ::tensorflow::RegisterTaskResponse>* AsyncRegisterTaskRaw(::grpc::ClientContext* context, const ::tensorflow::RegisterTaskRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::RegisterTaskResponse>* PrepareAsyncRegisterTaskRaw(::grpc::ClientContext* context, const ::tensorflow::RegisterTaskRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::HeartbeatResponse>* AsyncHeartbeatRaw(::grpc::ClientContext* context, const ::tensorflow::HeartbeatRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::HeartbeatResponse>* PrepareAsyncHeartbeatRaw(::grpc::ClientContext* context, const ::tensorflow::HeartbeatRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::WaitForAllTasksResponse>* AsyncWaitForAllTasksRaw(::grpc::ClientContext* context, const ::tensorflow::WaitForAllTasksRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::WaitForAllTasksResponse>* PrepareAsyncWaitForAllTasksRaw(::grpc::ClientContext* context, const ::tensorflow::WaitForAllTasksRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::ShutdownTaskResponse>* AsyncShutdownTaskRaw(::grpc::ClientContext* context, const ::tensorflow::ShutdownTaskRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::ShutdownTaskResponse>* PrepareAsyncShutdownTaskRaw(::grpc::ClientContext* context, const ::tensorflow::ShutdownTaskRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::ResetTaskResponse>* AsyncResetTaskRaw(::grpc::ClientContext* context, const ::tensorflow::ResetTaskRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::ResetTaskResponse>* PrepareAsyncResetTaskRaw(::grpc::ClientContext* context, const ::tensorflow::ResetTaskRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::ReportErrorToTaskResponse>* AsyncReportErrorToTaskRaw(::grpc::ClientContext* context, const ::tensorflow::ReportErrorToTaskRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::ReportErrorToTaskResponse>* PrepareAsyncReportErrorToTaskRaw(::grpc::ClientContext* context, const ::tensorflow::ReportErrorToTaskRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::ReportErrorToServiceResponse>* AsyncReportErrorToServiceRaw(::grpc::ClientContext* context, const ::tensorflow::ReportErrorToServiceRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::ReportErrorToServiceResponse>* PrepareAsyncReportErrorToServiceRaw(::grpc::ClientContext* context, const ::tensorflow::ReportErrorToServiceRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::InsertKeyValueResponse>* AsyncInsertKeyValueRaw(::grpc::ClientContext* context, const ::tensorflow::InsertKeyValueRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::InsertKeyValueResponse>* PrepareAsyncInsertKeyValueRaw(::grpc::ClientContext* context, const ::tensorflow::InsertKeyValueRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::GetKeyValueResponse>* AsyncGetKeyValueRaw(::grpc::ClientContext* context, const ::tensorflow::GetKeyValueRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::GetKeyValueResponse>* PrepareAsyncGetKeyValueRaw(::grpc::ClientContext* context, const ::tensorflow::GetKeyValueRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::DeleteKeyValueResponse>* AsyncDeleteKeyValueRaw(::grpc::ClientContext* context, const ::tensorflow::DeleteKeyValueRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::DeleteKeyValueResponse>* PrepareAsyncDeleteKeyValueRaw(::grpc::ClientContext* context, const ::tensorflow::DeleteKeyValueRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::BarrierResponse>* AsyncBarrierRaw(::grpc::ClientContext* context, const ::tensorflow::BarrierRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::BarrierResponse>* PrepareAsyncBarrierRaw(::grpc::ClientContext* context, const ::tensorflow::BarrierRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::CancelBarrierResponse>* AsyncCancelBarrierRaw(::grpc::ClientContext* context, const ::tensorflow::CancelBarrierRequest& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::tensorflow::CancelBarrierResponse>* PrepareAsyncCancelBarrierRaw(::grpc::ClientContext* context, const ::tensorflow::CancelBarrierRequest& request, ::grpc::CompletionQueue* cq) override;
    const ::grpc::internal::RpcMethod rpcmethod_RegisterTask_;
    const ::grpc::internal::RpcMethod rpcmethod_Heartbeat_;
    const ::grpc::internal::RpcMethod rpcmethod_WaitForAllTasks_;
    const ::grpc::internal::RpcMethod rpcmethod_ShutdownTask_;
    const ::grpc::internal::RpcMethod rpcmethod_ResetTask_;
    const ::grpc::internal::RpcMethod rpcmethod_ReportErrorToTask_;
    const ::grpc::internal::RpcMethod rpcmethod_ReportErrorToService_;
    const ::grpc::internal::RpcMethod rpcmethod_InsertKeyValue_;
    const ::grpc::internal::RpcMethod rpcmethod_GetKeyValue_;
    const ::grpc::internal::RpcMethod rpcmethod_DeleteKeyValue_;
    const ::grpc::internal::RpcMethod rpcmethod_Barrier_;
    const ::grpc::internal::RpcMethod rpcmethod_CancelBarrier_;
  };
  static std::unique_ptr<Stub> NewStub(const std::shared_ptr< ::grpc::ChannelInterface>& channel, const ::grpc::StubOptions& options = ::grpc::StubOptions());

  class Service : public ::grpc::Service {
   public:
    Service();
    virtual ~Service();
    // Register task to coordination service so that the service starts to track
    // liveness of the task. RPC blocks and returns only when it registers to
    // the service successfully, or error happens in the registering process.
    virtual ::grpc::Status RegisterTask(::grpc::ServerContext* context, const ::tensorflow::RegisterTaskRequest* request, ::tensorflow::RegisterTaskResponse* response);
    // Heartbeat message from task to coordination service. Heartbeat is sent from
    // a task to refresh its timestamp on leader to avoid it becoming stale.
    // RPC responds immediately after refreshing the timestamp on leader.
    virtual ::grpc::Status Heartbeat(::grpc::ServerContext* context, const ::tensorflow::HeartbeatRequest* request, ::tensorflow::HeartbeatResponse* response);
    // Wait for all tasks in the cluster to be up and running. The RPC request
    // only gets responded when all tasks have registered, or some error occurs.
    virtual ::grpc::Status WaitForAllTasks(::grpc::ServerContext* context, const ::tensorflow::WaitForAllTasksRequest* request, ::tensorflow::WaitForAllTasksResponse* response);
    // Disconnects task from the service. If `shutdown_barrier_timeout_in_ms` is
    // specified in the config, blocks until all tasks reach the barrier before
    // disconnecting together. If the barrier times out, tasks at the barrier will
    // still disconnect, while an error is reported to tasks that did not reach
    // the barrier on time.
    virtual ::grpc::Status ShutdownTask(::grpc::ServerContext* context, const ::tensorflow::ShutdownTaskRequest* request, ::tensorflow::ShutdownTaskResponse* response);
    // Disconnects task from the service if it is in an ERROR state, thereby
    // allowing it to reconnect via RegisterTask() in the future.
    virtual ::grpc::Status ResetTask(::grpc::ServerContext* context, const ::tensorflow::ResetTaskRequest* request, ::tensorflow::ResetTaskResponse* response);
    // Report error to the task. RPC sets the receiving instance of coordination
    // service agent to error state permanently.
    // TODO(b/195990880): Consider splitting this into a different RPC service.
    virtual ::grpc::Status ReportErrorToTask(::grpc::ServerContext* context, const ::tensorflow::ReportErrorToTaskRequest* request, ::tensorflow::ReportErrorToTaskResponse* response);
    // Report task error to coordination service. RPC sets the service-side task
    // state to error, and propagate the error to other tasks in the cluster.
    virtual ::grpc::Status ReportErrorToService(::grpc::ServerContext* context, const ::tensorflow::ReportErrorToServiceRequest* request, ::tensorflow::ReportErrorToServiceResponse* response);
    // Insert configuration key-value that will be accessible to all cluster
    // tasks. The key can be formatted as Unix file path with hierarchy. The
    // coordination service key-value store should only be used for cluster
    // configuration data.
    virtual ::grpc::Status InsertKeyValue(::grpc::ServerContext* context, const ::tensorflow::InsertKeyValueRequest* request, ::tensorflow::InsertKeyValueResponse* response);
    // Get configuration key-value. The request blocks until the key-value data
    // becomes available (i.e., set by a task in the cluster).
    virtual ::grpc::Status GetKeyValue(::grpc::ServerContext* context, const ::tensorflow::GetKeyValueRequest* request, ::tensorflow::GetKeyValueResponse* response);
    // Delete configuration key-value. If is_directory is set in request,
    // recursively clean up all key-values under the path specified by `key`.
    virtual ::grpc::Status DeleteKeyValue(::grpc::ServerContext* context, const ::tensorflow::DeleteKeyValueRequest* request, ::tensorflow::DeleteKeyValueResponse* response);
    // Blocks until all (or a subset of) tasks are at the barrier or the barrier
    // fails.
    //
    // `barrier_id` should be unique across barriers. Once the barrier has passed
    // or failed, subsequent calls will not block, and immediately respond with
    // the previous response.
    //
    // The first WaitAtBarrier() call received by the service for a particular
    // barrier id is special in that it determines the barrier deadline based on
    // timeout duration.
    // However, if subsequent calls by different agents specify a different set of
    // `tasks` for the same `barrier_id`, the barrier will fail instantly.
    //
    // If no tasks are specified (default), the barrier will block for all the
    // connected tasks.
    //
    // Possible service errors:
    //   - DeadlineExceeded: Timed out waiting for specified tasks at the barrier.
    //      Deadline is determined by the server timestamp when it receives the
    //      first WaitAtBarrier() + timeout duration.
    //   - Cancelled: One of the tasks called CancelBarrier().
    //   - Aborted: Service is shutting down.
    //   - Internal: Any participating task is in ERROR state.
    //   - InvalidArgument: (1) Conflicting tasks specified by different agents
    //       for the same barrier, (2) one of the participating tasks is not in
    //       the cluster, or (3) task making the request is not included in the
    //       list of participating tasks.
    virtual ::grpc::Status Barrier(::grpc::ServerContext* context, const ::tensorflow::BarrierRequest* request, ::tensorflow::BarrierResponse* response);
    // Aborts the barrier if it is ongoing.
    // Current and future WaitAtBarrier() calls with the same id will return a
    // CANCELLED error status.
    // Possible service errors:
    //   - FailedPrecondition: Barrier has already been passed.
    //   - NotFound: No barrier with the specified id is found.
    virtual ::grpc::Status CancelBarrier(::grpc::ServerContext* context, const ::tensorflow::CancelBarrierRequest* request, ::tensorflow::CancelBarrierResponse* response);
  };
  template <class BaseClass>
  class WithAsyncMethod_RegisterTask : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithAsyncMethod_RegisterTask() {
      ::grpc::Service::MarkMethodAsync(0);
    }
    ~WithAsyncMethod_RegisterTask() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status RegisterTask(::grpc::ServerContext* context, const ::tensorflow::RegisterTaskRequest* request, ::tensorflow::RegisterTaskResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestRegisterTask(::grpc::ServerContext* context, ::tensorflow::RegisterTaskRequest* request, ::grpc::ServerAsyncResponseWriter< ::tensorflow::RegisterTaskResponse>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(0, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithAsyncMethod_Heartbeat : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithAsyncMethod_Heartbeat() {
      ::grpc::Service::MarkMethodAsync(1);
    }
    ~WithAsyncMethod_Heartbeat() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status Heartbeat(::grpc::ServerContext* context, const ::tensorflow::HeartbeatRequest* request, ::tensorflow::HeartbeatResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestHeartbeat(::grpc::ServerContext* context, ::tensorflow::HeartbeatRequest* request, ::grpc::ServerAsyncResponseWriter< ::tensorflow::HeartbeatResponse>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(1, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithAsyncMethod_WaitForAllTasks : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithAsyncMethod_WaitForAllTasks() {
      ::grpc::Service::MarkMethodAsync(2);
    }
    ~WithAsyncMethod_WaitForAllTasks() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status WaitForAllTasks(::grpc::ServerContext* context, const ::tensorflow::WaitForAllTasksRequest* request, ::tensorflow::WaitForAllTasksResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestWaitForAllTasks(::grpc::ServerContext* context, ::tensorflow::WaitForAllTasksRequest* request, ::grpc::ServerAsyncResponseWriter< ::tensorflow::WaitForAllTasksResponse>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(2, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithAsyncMethod_ShutdownTask : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithAsyncMethod_ShutdownTask() {
      ::grpc::Service::MarkMethodAsync(3);
    }
    ~WithAsyncMethod_ShutdownTask() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status ShutdownTask(::grpc::ServerContext* context, const ::tensorflow::ShutdownTaskRequest* request, ::tensorflow::ShutdownTaskResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestShutdownTask(::grpc::ServerContext* context, ::tensorflow::ShutdownTaskRequest* request, ::grpc::ServerAsyncResponseWriter< ::tensorflow::ShutdownTaskResponse>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(3, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithAsyncMethod_ResetTask : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithAsyncMethod_ResetTask() {
      ::grpc::Service::MarkMethodAsync(4);
    }
    ~WithAsyncMethod_ResetTask() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status ResetTask(::grpc::ServerContext* context, const ::tensorflow::ResetTaskRequest* request, ::tensorflow::ResetTaskResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestResetTask(::grpc::ServerContext* context, ::tensorflow::ResetTaskRequest* request, ::grpc::ServerAsyncResponseWriter< ::tensorflow::ResetTaskResponse>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(4, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithAsyncMethod_ReportErrorToTask : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithAsyncMethod_ReportErrorToTask() {
      ::grpc::Service::MarkMethodAsync(5);
    }
    ~WithAsyncMethod_ReportErrorToTask() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status ReportErrorToTask(::grpc::ServerContext* context, const ::tensorflow::ReportErrorToTaskRequest* request, ::tensorflow::ReportErrorToTaskResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestReportErrorToTask(::grpc::ServerContext* context, ::tensorflow::ReportErrorToTaskRequest* request, ::grpc::ServerAsyncResponseWriter< ::tensorflow::ReportErrorToTaskResponse>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(5, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithAsyncMethod_ReportErrorToService : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithAsyncMethod_ReportErrorToService() {
      ::grpc::Service::MarkMethodAsync(6);
    }
    ~WithAsyncMethod_ReportErrorToService() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status ReportErrorToService(::grpc::ServerContext* context, const ::tensorflow::ReportErrorToServiceRequest* request, ::tensorflow::ReportErrorToServiceResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestReportErrorToService(::grpc::ServerContext* context, ::tensorflow::ReportErrorToServiceRequest* request, ::grpc::ServerAsyncResponseWriter< ::tensorflow::ReportErrorToServiceResponse>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(6, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithAsyncMethod_InsertKeyValue : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithAsyncMethod_InsertKeyValue() {
      ::grpc::Service::MarkMethodAsync(7);
    }
    ~WithAsyncMethod_InsertKeyValue() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status InsertKeyValue(::grpc::ServerContext* context, const ::tensorflow::InsertKeyValueRequest* request, ::tensorflow::InsertKeyValueResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestInsertKeyValue(::grpc::ServerContext* context, ::tensorflow::InsertKeyValueRequest* request, ::grpc::ServerAsyncResponseWriter< ::tensorflow::InsertKeyValueResponse>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(7, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithAsyncMethod_GetKeyValue : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithAsyncMethod_GetKeyValue() {
      ::grpc::Service::MarkMethodAsync(8);
    }
    ~WithAsyncMethod_GetKeyValue() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status GetKeyValue(::grpc::ServerContext* context, const ::tensorflow::GetKeyValueRequest* request, ::tensorflow::GetKeyValueResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestGetKeyValue(::grpc::ServerContext* context, ::tensorflow::GetKeyValueRequest* request, ::grpc::ServerAsyncResponseWriter< ::tensorflow::GetKeyValueResponse>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(8, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithAsyncMethod_DeleteKeyValue : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithAsyncMethod_DeleteKeyValue() {
      ::grpc::Service::MarkMethodAsync(9);
    }
    ~WithAsyncMethod_DeleteKeyValue() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status DeleteKeyValue(::grpc::ServerContext* context, const ::tensorflow::DeleteKeyValueRequest* request, ::tensorflow::DeleteKeyValueResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestDeleteKeyValue(::grpc::ServerContext* context, ::tensorflow::DeleteKeyValueRequest* request, ::grpc::ServerAsyncResponseWriter< ::tensorflow::DeleteKeyValueResponse>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(9, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithAsyncMethod_Barrier : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithAsyncMethod_Barrier() {
      ::grpc::Service::MarkMethodAsync(10);
    }
    ~WithAsyncMethod_Barrier() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status Barrier(::grpc::ServerContext* context, const ::tensorflow::BarrierRequest* request, ::tensorflow::BarrierResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestBarrier(::grpc::ServerContext* context, ::tensorflow::BarrierRequest* request, ::grpc::ServerAsyncResponseWriter< ::tensorflow::BarrierResponse>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(10, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithAsyncMethod_CancelBarrier : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithAsyncMethod_CancelBarrier() {
      ::grpc::Service::MarkMethodAsync(11);
    }
    ~WithAsyncMethod_CancelBarrier() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status CancelBarrier(::grpc::ServerContext* context, const ::tensorflow::CancelBarrierRequest* request, ::tensorflow::CancelBarrierResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestCancelBarrier(::grpc::ServerContext* context, ::tensorflow::CancelBarrierRequest* request, ::grpc::ServerAsyncResponseWriter< ::tensorflow::CancelBarrierResponse>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(11, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  typedef WithAsyncMethod_RegisterTask<WithAsyncMethod_Heartbeat<WithAsyncMethod_WaitForAllTasks<WithAsyncMethod_ShutdownTask<WithAsyncMethod_ResetTask<WithAsyncMethod_ReportErrorToTask<WithAsyncMethod_ReportErrorToService<WithAsyncMethod_InsertKeyValue<WithAsyncMethod_GetKeyValue<WithAsyncMethod_DeleteKeyValue<WithAsyncMethod_Barrier<WithAsyncMethod_CancelBarrier<Service > > > > > > > > > > > > AsyncService;
  template <class BaseClass>
  class WithGenericMethod_RegisterTask : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithGenericMethod_RegisterTask() {
      ::grpc::Service::MarkMethodGeneric(0);
    }
    ~WithGenericMethod_RegisterTask() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status RegisterTask(::grpc::ServerContext* context, const ::tensorflow::RegisterTaskRequest* request, ::tensorflow::RegisterTaskResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
  };
  template <class BaseClass>
  class WithGenericMethod_Heartbeat : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithGenericMethod_Heartbeat() {
      ::grpc::Service::MarkMethodGeneric(1);
    }
    ~WithGenericMethod_Heartbeat() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status Heartbeat(::grpc::ServerContext* context, const ::tensorflow::HeartbeatRequest* request, ::tensorflow::HeartbeatResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
  };
  template <class BaseClass>
  class WithGenericMethod_WaitForAllTasks : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithGenericMethod_WaitForAllTasks() {
      ::grpc::Service::MarkMethodGeneric(2);
    }
    ~WithGenericMethod_WaitForAllTasks() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status WaitForAllTasks(::grpc::ServerContext* context, const ::tensorflow::WaitForAllTasksRequest* request, ::tensorflow::WaitForAllTasksResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
  };
  template <class BaseClass>
  class WithGenericMethod_ShutdownTask : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithGenericMethod_ShutdownTask() {
      ::grpc::Service::MarkMethodGeneric(3);
    }
    ~WithGenericMethod_ShutdownTask() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status ShutdownTask(::grpc::ServerContext* context, const ::tensorflow::ShutdownTaskRequest* request, ::tensorflow::ShutdownTaskResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
  };
  template <class BaseClass>
  class WithGenericMethod_ResetTask : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithGenericMethod_ResetTask() {
      ::grpc::Service::MarkMethodGeneric(4);
    }
    ~WithGenericMethod_ResetTask() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status ResetTask(::grpc::ServerContext* context, const ::tensorflow::ResetTaskRequest* request, ::tensorflow::ResetTaskResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
  };
  template <class BaseClass>
  class WithGenericMethod_ReportErrorToTask : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithGenericMethod_ReportErrorToTask() {
      ::grpc::Service::MarkMethodGeneric(5);
    }
    ~WithGenericMethod_ReportErrorToTask() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status ReportErrorToTask(::grpc::ServerContext* context, const ::tensorflow::ReportErrorToTaskRequest* request, ::tensorflow::ReportErrorToTaskResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
  };
  template <class BaseClass>
  class WithGenericMethod_ReportErrorToService : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithGenericMethod_ReportErrorToService() {
      ::grpc::Service::MarkMethodGeneric(6);
    }
    ~WithGenericMethod_ReportErrorToService() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status ReportErrorToService(::grpc::ServerContext* context, const ::tensorflow::ReportErrorToServiceRequest* request, ::tensorflow::ReportErrorToServiceResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
  };
  template <class BaseClass>
  class WithGenericMethod_InsertKeyValue : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithGenericMethod_InsertKeyValue() {
      ::grpc::Service::MarkMethodGeneric(7);
    }
    ~WithGenericMethod_InsertKeyValue() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status InsertKeyValue(::grpc::ServerContext* context, const ::tensorflow::InsertKeyValueRequest* request, ::tensorflow::InsertKeyValueResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
  };
  template <class BaseClass>
  class WithGenericMethod_GetKeyValue : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithGenericMethod_GetKeyValue() {
      ::grpc::Service::MarkMethodGeneric(8);
    }
    ~WithGenericMethod_GetKeyValue() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status GetKeyValue(::grpc::ServerContext* context, const ::tensorflow::GetKeyValueRequest* request, ::tensorflow::GetKeyValueResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
  };
  template <class BaseClass>
  class WithGenericMethod_DeleteKeyValue : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithGenericMethod_DeleteKeyValue() {
      ::grpc::Service::MarkMethodGeneric(9);
    }
    ~WithGenericMethod_DeleteKeyValue() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status DeleteKeyValue(::grpc::ServerContext* context, const ::tensorflow::DeleteKeyValueRequest* request, ::tensorflow::DeleteKeyValueResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
  };
  template <class BaseClass>
  class WithGenericMethod_Barrier : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithGenericMethod_Barrier() {
      ::grpc::Service::MarkMethodGeneric(10);
    }
    ~WithGenericMethod_Barrier() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status Barrier(::grpc::ServerContext* context, const ::tensorflow::BarrierRequest* request, ::tensorflow::BarrierResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
  };
  template <class BaseClass>
  class WithGenericMethod_CancelBarrier : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithGenericMethod_CancelBarrier() {
      ::grpc::Service::MarkMethodGeneric(11);
    }
    ~WithGenericMethod_CancelBarrier() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status CancelBarrier(::grpc::ServerContext* context, const ::tensorflow::CancelBarrierRequest* request, ::tensorflow::CancelBarrierResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
  };
  template <class BaseClass>
  class WithRawMethod_RegisterTask : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithRawMethod_RegisterTask() {
      ::grpc::Service::MarkMethodRaw(0);
    }
    ~WithRawMethod_RegisterTask() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status RegisterTask(::grpc::ServerContext* context, const ::tensorflow::RegisterTaskRequest* request, ::tensorflow::RegisterTaskResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestRegisterTask(::grpc::ServerContext* context, ::grpc::ByteBuffer* request, ::grpc::ServerAsyncResponseWriter< ::grpc::ByteBuffer>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(0, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithRawMethod_Heartbeat : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithRawMethod_Heartbeat() {
      ::grpc::Service::MarkMethodRaw(1);
    }
    ~WithRawMethod_Heartbeat() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status Heartbeat(::grpc::ServerContext* context, const ::tensorflow::HeartbeatRequest* request, ::tensorflow::HeartbeatResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestHeartbeat(::grpc::ServerContext* context, ::grpc::ByteBuffer* request, ::grpc::ServerAsyncResponseWriter< ::grpc::ByteBuffer>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(1, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithRawMethod_WaitForAllTasks : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithRawMethod_WaitForAllTasks() {
      ::grpc::Service::MarkMethodRaw(2);
    }
    ~WithRawMethod_WaitForAllTasks() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status WaitForAllTasks(::grpc::ServerContext* context, const ::tensorflow::WaitForAllTasksRequest* request, ::tensorflow::WaitForAllTasksResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestWaitForAllTasks(::grpc::ServerContext* context, ::grpc::ByteBuffer* request, ::grpc::ServerAsyncResponseWriter< ::grpc::ByteBuffer>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(2, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithRawMethod_ShutdownTask : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithRawMethod_ShutdownTask() {
      ::grpc::Service::MarkMethodRaw(3);
    }
    ~WithRawMethod_ShutdownTask() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status ShutdownTask(::grpc::ServerContext* context, const ::tensorflow::ShutdownTaskRequest* request, ::tensorflow::ShutdownTaskResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestShutdownTask(::grpc::ServerContext* context, ::grpc::ByteBuffer* request, ::grpc::ServerAsyncResponseWriter< ::grpc::ByteBuffer>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(3, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithRawMethod_ResetTask : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithRawMethod_ResetTask() {
      ::grpc::Service::MarkMethodRaw(4);
    }
    ~WithRawMethod_ResetTask() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status ResetTask(::grpc::ServerContext* context, const ::tensorflow::ResetTaskRequest* request, ::tensorflow::ResetTaskResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestResetTask(::grpc::ServerContext* context, ::grpc::ByteBuffer* request, ::grpc::ServerAsyncResponseWriter< ::grpc::ByteBuffer>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(4, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithRawMethod_ReportErrorToTask : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithRawMethod_ReportErrorToTask() {
      ::grpc::Service::MarkMethodRaw(5);
    }
    ~WithRawMethod_ReportErrorToTask() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status ReportErrorToTask(::grpc::ServerContext* context, const ::tensorflow::ReportErrorToTaskRequest* request, ::tensorflow::ReportErrorToTaskResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestReportErrorToTask(::grpc::ServerContext* context, ::grpc::ByteBuffer* request, ::grpc::ServerAsyncResponseWriter< ::grpc::ByteBuffer>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(5, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithRawMethod_ReportErrorToService : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithRawMethod_ReportErrorToService() {
      ::grpc::Service::MarkMethodRaw(6);
    }
    ~WithRawMethod_ReportErrorToService() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status ReportErrorToService(::grpc::ServerContext* context, const ::tensorflow::ReportErrorToServiceRequest* request, ::tensorflow::ReportErrorToServiceResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestReportErrorToService(::grpc::ServerContext* context, ::grpc::ByteBuffer* request, ::grpc::ServerAsyncResponseWriter< ::grpc::ByteBuffer>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(6, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithRawMethod_InsertKeyValue : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithRawMethod_InsertKeyValue() {
      ::grpc::Service::MarkMethodRaw(7);
    }
    ~WithRawMethod_InsertKeyValue() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status InsertKeyValue(::grpc::ServerContext* context, const ::tensorflow::InsertKeyValueRequest* request, ::tensorflow::InsertKeyValueResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestInsertKeyValue(::grpc::ServerContext* context, ::grpc::ByteBuffer* request, ::grpc::ServerAsyncResponseWriter< ::grpc::ByteBuffer>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(7, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithRawMethod_GetKeyValue : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithRawMethod_GetKeyValue() {
      ::grpc::Service::MarkMethodRaw(8);
    }
    ~WithRawMethod_GetKeyValue() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status GetKeyValue(::grpc::ServerContext* context, const ::tensorflow::GetKeyValueRequest* request, ::tensorflow::GetKeyValueResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestGetKeyValue(::grpc::ServerContext* context, ::grpc::ByteBuffer* request, ::grpc::ServerAsyncResponseWriter< ::grpc::ByteBuffer>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(8, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithRawMethod_DeleteKeyValue : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithRawMethod_DeleteKeyValue() {
      ::grpc::Service::MarkMethodRaw(9);
    }
    ~WithRawMethod_DeleteKeyValue() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status DeleteKeyValue(::grpc::ServerContext* context, const ::tensorflow::DeleteKeyValueRequest* request, ::tensorflow::DeleteKeyValueResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestDeleteKeyValue(::grpc::ServerContext* context, ::grpc::ByteBuffer* request, ::grpc::ServerAsyncResponseWriter< ::grpc::ByteBuffer>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(9, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithRawMethod_Barrier : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithRawMethod_Barrier() {
      ::grpc::Service::MarkMethodRaw(10);
    }
    ~WithRawMethod_Barrier() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status Barrier(::grpc::ServerContext* context, const ::tensorflow::BarrierRequest* request, ::tensorflow::BarrierResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestBarrier(::grpc::ServerContext* context, ::grpc::ByteBuffer* request, ::grpc::ServerAsyncResponseWriter< ::grpc::ByteBuffer>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(10, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithRawMethod_CancelBarrier : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithRawMethod_CancelBarrier() {
      ::grpc::Service::MarkMethodRaw(11);
    }
    ~WithRawMethod_CancelBarrier() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status CancelBarrier(::grpc::ServerContext* context, const ::tensorflow::CancelBarrierRequest* request, ::tensorflow::CancelBarrierResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestCancelBarrier(::grpc::ServerContext* context, ::grpc::ByteBuffer* request, ::grpc::ServerAsyncResponseWriter< ::grpc::ByteBuffer>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(11, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithStreamedUnaryMethod_RegisterTask : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithStreamedUnaryMethod_RegisterTask() {
      ::grpc::Service::MarkMethodStreamed(0,
        new ::grpc::internal::StreamedUnaryHandler< ::tensorflow::RegisterTaskRequest, ::tensorflow::RegisterTaskResponse>(std::bind(&WithStreamedUnaryMethod_RegisterTask<BaseClass>::StreamedRegisterTask, this, std::placeholders::_1, std::placeholders::_2)));
    }
    ~WithStreamedUnaryMethod_RegisterTask() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable regular version of this method
    ::grpc::Status RegisterTask(::grpc::ServerContext* context, const ::tensorflow::RegisterTaskRequest* request, ::tensorflow::RegisterTaskResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    // replace default version of method with streamed unary
    virtual ::grpc::Status StreamedRegisterTask(::grpc::ServerContext* context, ::grpc::ServerUnaryStreamer< ::tensorflow::RegisterTaskRequest,::tensorflow::RegisterTaskResponse>* server_unary_streamer) = 0;
  };
  template <class BaseClass>
  class WithStreamedUnaryMethod_Heartbeat : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithStreamedUnaryMethod_Heartbeat() {
      ::grpc::Service::MarkMethodStreamed(1,
        new ::grpc::internal::StreamedUnaryHandler< ::tensorflow::HeartbeatRequest, ::tensorflow::HeartbeatResponse>(std::bind(&WithStreamedUnaryMethod_Heartbeat<BaseClass>::StreamedHeartbeat, this, std::placeholders::_1, std::placeholders::_2)));
    }
    ~WithStreamedUnaryMethod_Heartbeat() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable regular version of this method
    ::grpc::Status Heartbeat(::grpc::ServerContext* context, const ::tensorflow::HeartbeatRequest* request, ::tensorflow::HeartbeatResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    // replace default version of method with streamed unary
    virtual ::grpc::Status StreamedHeartbeat(::grpc::ServerContext* context, ::grpc::ServerUnaryStreamer< ::tensorflow::HeartbeatRequest,::tensorflow::HeartbeatResponse>* server_unary_streamer) = 0;
  };
  template <class BaseClass>
  class WithStreamedUnaryMethod_WaitForAllTasks : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithStreamedUnaryMethod_WaitForAllTasks() {
      ::grpc::Service::MarkMethodStreamed(2,
        new ::grpc::internal::StreamedUnaryHandler< ::tensorflow::WaitForAllTasksRequest, ::tensorflow::WaitForAllTasksResponse>(std::bind(&WithStreamedUnaryMethod_WaitForAllTasks<BaseClass>::StreamedWaitForAllTasks, this, std::placeholders::_1, std::placeholders::_2)));
    }
    ~WithStreamedUnaryMethod_WaitForAllTasks() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable regular version of this method
    ::grpc::Status WaitForAllTasks(::grpc::ServerContext* context, const ::tensorflow::WaitForAllTasksRequest* request, ::tensorflow::WaitForAllTasksResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    // replace default version of method with streamed unary
    virtual ::grpc::Status StreamedWaitForAllTasks(::grpc::ServerContext* context, ::grpc::ServerUnaryStreamer< ::tensorflow::WaitForAllTasksRequest,::tensorflow::WaitForAllTasksResponse>* server_unary_streamer) = 0;
  };
  template <class BaseClass>
  class WithStreamedUnaryMethod_ShutdownTask : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithStreamedUnaryMethod_ShutdownTask() {
      ::grpc::Service::MarkMethodStreamed(3,
        new ::grpc::internal::StreamedUnaryHandler< ::tensorflow::ShutdownTaskRequest, ::tensorflow::ShutdownTaskResponse>(std::bind(&WithStreamedUnaryMethod_ShutdownTask<BaseClass>::StreamedShutdownTask, this, std::placeholders::_1, std::placeholders::_2)));
    }
    ~WithStreamedUnaryMethod_ShutdownTask() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable regular version of this method
    ::grpc::Status ShutdownTask(::grpc::ServerContext* context, const ::tensorflow::ShutdownTaskRequest* request, ::tensorflow::ShutdownTaskResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    // replace default version of method with streamed unary
    virtual ::grpc::Status StreamedShutdownTask(::grpc::ServerContext* context, ::grpc::ServerUnaryStreamer< ::tensorflow::ShutdownTaskRequest,::tensorflow::ShutdownTaskResponse>* server_unary_streamer) = 0;
  };
  template <class BaseClass>
  class WithStreamedUnaryMethod_ResetTask : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithStreamedUnaryMethod_ResetTask() {
      ::grpc::Service::MarkMethodStreamed(4,
        new ::grpc::internal::StreamedUnaryHandler< ::tensorflow::ResetTaskRequest, ::tensorflow::ResetTaskResponse>(std::bind(&WithStreamedUnaryMethod_ResetTask<BaseClass>::StreamedResetTask, this, std::placeholders::_1, std::placeholders::_2)));
    }
    ~WithStreamedUnaryMethod_ResetTask() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable regular version of this method
    ::grpc::Status ResetTask(::grpc::ServerContext* context, const ::tensorflow::ResetTaskRequest* request, ::tensorflow::ResetTaskResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    // replace default version of method with streamed unary
    virtual ::grpc::Status StreamedResetTask(::grpc::ServerContext* context, ::grpc::ServerUnaryStreamer< ::tensorflow::ResetTaskRequest,::tensorflow::ResetTaskResponse>* server_unary_streamer) = 0;
  };
  template <class BaseClass>
  class WithStreamedUnaryMethod_ReportErrorToTask : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithStreamedUnaryMethod_ReportErrorToTask() {
      ::grpc::Service::MarkMethodStreamed(5,
        new ::grpc::internal::StreamedUnaryHandler< ::tensorflow::ReportErrorToTaskRequest, ::tensorflow::ReportErrorToTaskResponse>(std::bind(&WithStreamedUnaryMethod_ReportErrorToTask<BaseClass>::StreamedReportErrorToTask, this, std::placeholders::_1, std::placeholders::_2)));
    }
    ~WithStreamedUnaryMethod_ReportErrorToTask() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable regular version of this method
    ::grpc::Status ReportErrorToTask(::grpc::ServerContext* context, const ::tensorflow::ReportErrorToTaskRequest* request, ::tensorflow::ReportErrorToTaskResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    // replace default version of method with streamed unary
    virtual ::grpc::Status StreamedReportErrorToTask(::grpc::ServerContext* context, ::grpc::ServerUnaryStreamer< ::tensorflow::ReportErrorToTaskRequest,::tensorflow::ReportErrorToTaskResponse>* server_unary_streamer) = 0;
  };
  template <class BaseClass>
  class WithStreamedUnaryMethod_ReportErrorToService : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithStreamedUnaryMethod_ReportErrorToService() {
      ::grpc::Service::MarkMethodStreamed(6,
        new ::grpc::internal::StreamedUnaryHandler< ::tensorflow::ReportErrorToServiceRequest, ::tensorflow::ReportErrorToServiceResponse>(std::bind(&WithStreamedUnaryMethod_ReportErrorToService<BaseClass>::StreamedReportErrorToService, this, std::placeholders::_1, std::placeholders::_2)));
    }
    ~WithStreamedUnaryMethod_ReportErrorToService() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable regular version of this method
    ::grpc::Status ReportErrorToService(::grpc::ServerContext* context, const ::tensorflow::ReportErrorToServiceRequest* request, ::tensorflow::ReportErrorToServiceResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    // replace default version of method with streamed unary
    virtual ::grpc::Status StreamedReportErrorToService(::grpc::ServerContext* context, ::grpc::ServerUnaryStreamer< ::tensorflow::ReportErrorToServiceRequest,::tensorflow::ReportErrorToServiceResponse>* server_unary_streamer) = 0;
  };
  template <class BaseClass>
  class WithStreamedUnaryMethod_InsertKeyValue : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithStreamedUnaryMethod_InsertKeyValue() {
      ::grpc::Service::MarkMethodStreamed(7,
        new ::grpc::internal::StreamedUnaryHandler< ::tensorflow::InsertKeyValueRequest, ::tensorflow::InsertKeyValueResponse>(std::bind(&WithStreamedUnaryMethod_InsertKeyValue<BaseClass>::StreamedInsertKeyValue, this, std::placeholders::_1, std::placeholders::_2)));
    }
    ~WithStreamedUnaryMethod_InsertKeyValue() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable regular version of this method
    ::grpc::Status InsertKeyValue(::grpc::ServerContext* context, const ::tensorflow::InsertKeyValueRequest* request, ::tensorflow::InsertKeyValueResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    // replace default version of method with streamed unary
    virtual ::grpc::Status StreamedInsertKeyValue(::grpc::ServerContext* context, ::grpc::ServerUnaryStreamer< ::tensorflow::InsertKeyValueRequest,::tensorflow::InsertKeyValueResponse>* server_unary_streamer) = 0;
  };
  template <class BaseClass>
  class WithStreamedUnaryMethod_GetKeyValue : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithStreamedUnaryMethod_GetKeyValue() {
      ::grpc::Service::MarkMethodStreamed(8,
        new ::grpc::internal::StreamedUnaryHandler< ::tensorflow::GetKeyValueRequest, ::tensorflow::GetKeyValueResponse>(std::bind(&WithStreamedUnaryMethod_GetKeyValue<BaseClass>::StreamedGetKeyValue, this, std::placeholders::_1, std::placeholders::_2)));
    }
    ~WithStreamedUnaryMethod_GetKeyValue() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable regular version of this method
    ::grpc::Status GetKeyValue(::grpc::ServerContext* context, const ::tensorflow::GetKeyValueRequest* request, ::tensorflow::GetKeyValueResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    // replace default version of method with streamed unary
    virtual ::grpc::Status StreamedGetKeyValue(::grpc::ServerContext* context, ::grpc::ServerUnaryStreamer< ::tensorflow::GetKeyValueRequest,::tensorflow::GetKeyValueResponse>* server_unary_streamer) = 0;
  };
  template <class BaseClass>
  class WithStreamedUnaryMethod_DeleteKeyValue : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithStreamedUnaryMethod_DeleteKeyValue() {
      ::grpc::Service::MarkMethodStreamed(9,
        new ::grpc::internal::StreamedUnaryHandler< ::tensorflow::DeleteKeyValueRequest, ::tensorflow::DeleteKeyValueResponse>(std::bind(&WithStreamedUnaryMethod_DeleteKeyValue<BaseClass>::StreamedDeleteKeyValue, this, std::placeholders::_1, std::placeholders::_2)));
    }
    ~WithStreamedUnaryMethod_DeleteKeyValue() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable regular version of this method
    ::grpc::Status DeleteKeyValue(::grpc::ServerContext* context, const ::tensorflow::DeleteKeyValueRequest* request, ::tensorflow::DeleteKeyValueResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    // replace default version of method with streamed unary
    virtual ::grpc::Status StreamedDeleteKeyValue(::grpc::ServerContext* context, ::grpc::ServerUnaryStreamer< ::tensorflow::DeleteKeyValueRequest,::tensorflow::DeleteKeyValueResponse>* server_unary_streamer) = 0;
  };
  template <class BaseClass>
  class WithStreamedUnaryMethod_Barrier : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithStreamedUnaryMethod_Barrier() {
      ::grpc::Service::MarkMethodStreamed(10,
        new ::grpc::internal::StreamedUnaryHandler< ::tensorflow::BarrierRequest, ::tensorflow::BarrierResponse>(std::bind(&WithStreamedUnaryMethod_Barrier<BaseClass>::StreamedBarrier, this, std::placeholders::_1, std::placeholders::_2)));
    }
    ~WithStreamedUnaryMethod_Barrier() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable regular version of this method
    ::grpc::Status Barrier(::grpc::ServerContext* context, const ::tensorflow::BarrierRequest* request, ::tensorflow::BarrierResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    // replace default version of method with streamed unary
    virtual ::grpc::Status StreamedBarrier(::grpc::ServerContext* context, ::grpc::ServerUnaryStreamer< ::tensorflow::BarrierRequest,::tensorflow::BarrierResponse>* server_unary_streamer) = 0;
  };
  template <class BaseClass>
  class WithStreamedUnaryMethod_CancelBarrier : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service *service) {}
   public:
    WithStreamedUnaryMethod_CancelBarrier() {
      ::grpc::Service::MarkMethodStreamed(11,
        new ::grpc::internal::StreamedUnaryHandler< ::tensorflow::CancelBarrierRequest, ::tensorflow::CancelBarrierResponse>(std::bind(&WithStreamedUnaryMethod_CancelBarrier<BaseClass>::StreamedCancelBarrier, this, std::placeholders::_1, std::placeholders::_2)));
    }
    ~WithStreamedUnaryMethod_CancelBarrier() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable regular version of this method
    ::grpc::Status CancelBarrier(::grpc::ServerContext* context, const ::tensorflow::CancelBarrierRequest* request, ::tensorflow::CancelBarrierResponse* response) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    // replace default version of method with streamed unary
    virtual ::grpc::Status StreamedCancelBarrier(::grpc::ServerContext* context, ::grpc::ServerUnaryStreamer< ::tensorflow::CancelBarrierRequest,::tensorflow::CancelBarrierResponse>* server_unary_streamer) = 0;
  };
  typedef WithStreamedUnaryMethod_RegisterTask<WithStreamedUnaryMethod_Heartbeat<WithStreamedUnaryMethod_WaitForAllTasks<WithStreamedUnaryMethod_ShutdownTask<WithStreamedUnaryMethod_ResetTask<WithStreamedUnaryMethod_ReportErrorToTask<WithStreamedUnaryMethod_ReportErrorToService<WithStreamedUnaryMethod_InsertKeyValue<WithStreamedUnaryMethod_GetKeyValue<WithStreamedUnaryMethod_DeleteKeyValue<WithStreamedUnaryMethod_Barrier<WithStreamedUnaryMethod_CancelBarrier<Service > > > > > > > > > > > > StreamedUnaryService;
  typedef Service SplitStreamedService;
  typedef WithStreamedUnaryMethod_RegisterTask<WithStreamedUnaryMethod_Heartbeat<WithStreamedUnaryMethod_WaitForAllTasks<WithStreamedUnaryMethod_ShutdownTask<WithStreamedUnaryMethod_ResetTask<WithStreamedUnaryMethod_ReportErrorToTask<WithStreamedUnaryMethod_ReportErrorToService<WithStreamedUnaryMethod_InsertKeyValue<WithStreamedUnaryMethod_GetKeyValue<WithStreamedUnaryMethod_DeleteKeyValue<WithStreamedUnaryMethod_Barrier<WithStreamedUnaryMethod_CancelBarrier<Service > > > > > > > > > > > > StreamedService;
};

}  // namespace tensorflow


#endif  // GRPC_tensorflow_2fcore_2fprotobuf_2fcoordination_5fservice_2eproto__INCLUDED
