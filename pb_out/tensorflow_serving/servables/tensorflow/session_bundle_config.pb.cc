// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow_serving/servables/tensorflow/session_bundle_config.proto

#include "tensorflow_serving/servables/tensorflow/session_bundle_config.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/port.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// This is a temporary google only hack
#ifdef GOOGLE_PROTOBUF_ENFORCE_UNIQUENESS
#include "third_party/protobuf/version.h"
#endif
// @@protoc_insertion_point(includes)

namespace protobuf_google_2fprotobuf_2fwrappers_2eproto {
extern PROTOBUF_INTERNAL_EXPORT_protobuf_google_2fprotobuf_2fwrappers_2eproto ::google::protobuf::internal::SCCInfo<0> scc_info_BoolValue;
extern PROTOBUF_INTERNAL_EXPORT_protobuf_google_2fprotobuf_2fwrappers_2eproto ::google::protobuf::internal::SCCInfo<0> scc_info_Int32Value;
extern PROTOBUF_INTERNAL_EXPORT_protobuf_google_2fprotobuf_2fwrappers_2eproto ::google::protobuf::internal::SCCInfo<0> scc_info_Int64Value;
extern PROTOBUF_INTERNAL_EXPORT_protobuf_google_2fprotobuf_2fwrappers_2eproto ::google::protobuf::internal::SCCInfo<0> scc_info_StringValue;
}  // namespace protobuf_google_2fprotobuf_2fwrappers_2eproto
namespace protobuf_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto {
extern PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto ::google::protobuf::internal::SCCInfo<7> scc_info_ConfigProto;
}  // namespace protobuf_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto
namespace protobuf_tensorflow_2fcore_2fprotobuf_2fnamed_5ftensor_2eproto {
extern PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_2fcore_2fprotobuf_2fnamed_5ftensor_2eproto ::google::protobuf::internal::SCCInfo<1> scc_info_NamedTensorProto;
}  // namespace protobuf_tensorflow_2fcore_2fprotobuf_2fnamed_5ftensor_2eproto
namespace protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto {
extern PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto ::google::protobuf::internal::SCCInfo<1> scc_info_ModelWarmupOptions;
extern PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto ::google::protobuf::internal::SCCInfo<3> scc_info_BatchingParameters;
}  // namespace protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto
namespace tensorflow {
namespace serving {
class ModelWarmupOptionsDefaultTypeInternal {
 public:
  ::google::protobuf::internal::ExplicitlyConstructed<ModelWarmupOptions>
      _instance;
} _ModelWarmupOptions_default_instance_;
class SessionBundleConfigDefaultTypeInternal {
 public:
  ::google::protobuf::internal::ExplicitlyConstructed<SessionBundleConfig>
      _instance;
} _SessionBundleConfig_default_instance_;
class BatchingParametersDefaultTypeInternal {
 public:
  ::google::protobuf::internal::ExplicitlyConstructed<BatchingParameters>
      _instance;
} _BatchingParameters_default_instance_;
}  // namespace serving
}  // namespace tensorflow
namespace protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto {
static void InitDefaultsModelWarmupOptions() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::tensorflow::serving::_ModelWarmupOptions_default_instance_;
    new (ptr) ::tensorflow::serving::ModelWarmupOptions();
    ::google::protobuf::internal::OnShutdownDestroyMessage(ptr);
  }
  ::tensorflow::serving::ModelWarmupOptions::InitAsDefaultInstance();
}

::google::protobuf::internal::SCCInfo<1> scc_info_ModelWarmupOptions =
    {{ATOMIC_VAR_INIT(::google::protobuf::internal::SCCInfoBase::kUninitialized), 1, InitDefaultsModelWarmupOptions}, {
      &protobuf_google_2fprotobuf_2fwrappers_2eproto::scc_info_Int32Value.base,}};

static void InitDefaultsSessionBundleConfig() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::tensorflow::serving::_SessionBundleConfig_default_instance_;
    new (ptr) ::tensorflow::serving::SessionBundleConfig();
    ::google::protobuf::internal::OnShutdownDestroyMessage(ptr);
  }
  ::tensorflow::serving::SessionBundleConfig::InitAsDefaultInstance();
}

::google::protobuf::internal::SCCInfo<5> scc_info_SessionBundleConfig =
    {{ATOMIC_VAR_INIT(::google::protobuf::internal::SCCInfoBase::kUninitialized), 5, InitDefaultsSessionBundleConfig}, {
      &protobuf_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto::scc_info_ConfigProto.base,
      &protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::scc_info_BatchingParameters.base,
      &protobuf_google_2fprotobuf_2fwrappers_2eproto::scc_info_Int32Value.base,
      &protobuf_tensorflow_2fcore_2fprotobuf_2fnamed_5ftensor_2eproto::scc_info_NamedTensorProto.base,
      &protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::scc_info_ModelWarmupOptions.base,}};

static void InitDefaultsBatchingParameters() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::tensorflow::serving::_BatchingParameters_default_instance_;
    new (ptr) ::tensorflow::serving::BatchingParameters();
    ::google::protobuf::internal::OnShutdownDestroyMessage(ptr);
  }
  ::tensorflow::serving::BatchingParameters::InitAsDefaultInstance();
}

::google::protobuf::internal::SCCInfo<3> scc_info_BatchingParameters =
    {{ATOMIC_VAR_INIT(::google::protobuf::internal::SCCInfoBase::kUninitialized), 3, InitDefaultsBatchingParameters}, {
      &protobuf_google_2fprotobuf_2fwrappers_2eproto::scc_info_Int64Value.base,
      &protobuf_google_2fprotobuf_2fwrappers_2eproto::scc_info_StringValue.base,
      &protobuf_google_2fprotobuf_2fwrappers_2eproto::scc_info_BoolValue.base,}};

void InitDefaults() {
  ::google::protobuf::internal::InitSCC(&scc_info_ModelWarmupOptions.base);
  ::google::protobuf::internal::InitSCC(&scc_info_SessionBundleConfig.base);
  ::google::protobuf::internal::InitSCC(&scc_info_BatchingParameters.base);
}

::google::protobuf::Metadata file_level_metadata[3];

const ::google::protobuf::uint32 TableStruct::offsets[] GOOGLE_PROTOBUF_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
  ~0u,  // no _has_bits_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::ModelWarmupOptions, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::ModelWarmupOptions, num_request_iterations_),
  ~0u,  // no _has_bits_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionBundleConfig, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionBundleConfig, session_target_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionBundleConfig, session_config_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionBundleConfig, batching_parameters_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionBundleConfig, session_run_load_threadpool_index_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionBundleConfig, experimental_transient_ram_bytes_during_load_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionBundleConfig, saved_model_tags_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionBundleConfig, experimental_fixed_input_tensors_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionBundleConfig, enable_model_warmup_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionBundleConfig, model_warmup_options_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionBundleConfig, enable_session_metadata_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionBundleConfig, remove_unused_fields_from_bundle_metagraph_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionBundleConfig, prefer_tflite_model_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionBundleConfig, resource_estimation_uses_validation_result_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionBundleConfig, num_tflite_interpreters_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionBundleConfig, num_tflite_interpreters_per_pool_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionBundleConfig, num_tflite_pools_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionBundleConfig, wrap_session_with_no_threading_params_),
  ~0u,  // no _has_bits_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::BatchingParameters, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::BatchingParameters, max_batch_size_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::BatchingParameters, batch_timeout_micros_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::BatchingParameters, max_enqueued_batches_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::BatchingParameters, num_batch_threads_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::BatchingParameters, thread_pool_name_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::BatchingParameters, enable_large_batch_splitting_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::BatchingParameters, max_execution_batch_size_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::BatchingParameters, allowed_batch_sizes_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::BatchingParameters, pad_variable_length_inputs_),
};
static const ::google::protobuf::internal::MigrationSchema schemas[] GOOGLE_PROTOBUF_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
  { 0, -1, sizeof(::tensorflow::serving::ModelWarmupOptions)},
  { 6, -1, sizeof(::tensorflow::serving::SessionBundleConfig)},
  { 28, -1, sizeof(::tensorflow::serving::BatchingParameters)},
};

static ::google::protobuf::Message const * const file_default_instances[] = {
  reinterpret_cast<const ::google::protobuf::Message*>(&::tensorflow::serving::_ModelWarmupOptions_default_instance_),
  reinterpret_cast<const ::google::protobuf::Message*>(&::tensorflow::serving::_SessionBundleConfig_default_instance_),
  reinterpret_cast<const ::google::protobuf::Message*>(&::tensorflow::serving::_BatchingParameters_default_instance_),
};

void protobuf_AssignDescriptors() {
  AddDescriptors();
  AssignDescriptors(
      "tensorflow_serving/servables/tensorflow/session_bundle_config.proto", schemas, file_default_instances, TableStruct::offsets,
      file_level_metadata, NULL, NULL);
}

void protobuf_AssignDescriptorsOnce() {
  static ::google::protobuf::internal::once_flag once;
  ::google::protobuf::internal::call_once(once, protobuf_AssignDescriptors);
}

void protobuf_RegisterTypes(const ::std::string&) GOOGLE_PROTOBUF_ATTRIBUTE_COLD;
void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::internal::RegisterAllTypes(file_level_metadata, 3);
}

void AddDescriptorsImpl() {
  InitDefaults();
  static const char descriptor[] GOOGLE_PROTOBUF_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
      "\nCtensorflow_serving/servables/tensorflo"
      "w/session_bundle_config.proto\022\022tensorflo"
      "w.serving\032\036google/protobuf/wrappers.prot"
      "o\032%tensorflow/core/protobuf/config.proto"
      "\032+tensorflow/core/protobuf/named_tensor."
      "proto\"Q\n\022ModelWarmupOptions\022;\n\026num_reque"
      "st_iterations\030\001 \001(\0132\033.google.protobuf.In"
      "t32Value\"\257\006\n\023SessionBundleConfig\022\026\n\016sess"
      "ion_target\030\001 \001(\t\022/\n\016session_config\030\002 \001(\013"
      "2\027.tensorflow.ConfigProto\022C\n\023batching_pa"
      "rameters\030\003 \001(\0132&.tensorflow.serving.Batc"
      "hingParameters\022F\n!session_run_load_threa"
      "dpool_index\030\004 \001(\0132\033.google.protobuf.Int3"
      "2Value\0224\n,experimental_transient_ram_byt"
      "es_during_load\030\005 \001(\004\022\030\n\020saved_model_tags"
      "\030\006 \003(\t\022G\n experimental_fixed_input_tenso"
      "rs\030\212\006 \003(\0132\034.tensorflow.NamedTensorProto\022"
      "\034\n\023enable_model_warmup\030\213\006 \001(\010\022E\n\024model_w"
      "armup_options\030\214\006 \001(\0132&.tensorflow.servin"
      "g.ModelWarmupOptions\022 \n\027enable_session_m"
      "etadata\030\215\006 \001(\010\0223\n*remove_unused_fields_f"
      "rom_bundle_metagraph\030\216\006 \001(\010\022\034\n\023prefer_tf"
      "lite_model\030\217\006 \001(\010\0223\n*resource_estimation"
      "_uses_validation_result\030\220\006 \001(\010\022$\n\027num_tf"
      "lite_interpreters\030\221\006 \001(\005B\002\030\001\022)\n num_tfli"
      "te_interpreters_per_pool\030\222\006 \001(\005\022\031\n\020num_t"
      "flite_pools\030\223\006 \001(\005\022.\n%wrap_session_with_"
      "no_threading_params\030\224\006 \001(\010\"\361\003\n\022BatchingP"
      "arameters\0223\n\016max_batch_size\030\001 \001(\0132\033.goog"
      "le.protobuf.Int64Value\0229\n\024batch_timeout_"
      "micros\030\002 \001(\0132\033.google.protobuf.Int64Valu"
      "e\0229\n\024max_enqueued_batches\030\003 \001(\0132\033.google"
      ".protobuf.Int64Value\0226\n\021num_batch_thread"
      "s\030\004 \001(\0132\033.google.protobuf.Int64Value\0226\n\020"
      "thread_pool_name\030\005 \001(\0132\034.google.protobuf"
      ".StringValue\022@\n\034enable_large_batch_split"
      "ting\030\010 \001(\0132\032.google.protobuf.BoolValue\022="
      "\n\030max_execution_batch_size\030\t \001(\0132\033.googl"
      "e.protobuf.Int64Value\022\033\n\023allowed_batch_s"
      "izes\030\006 \003(\003\022\"\n\032pad_variable_length_inputs"
      "\030\007 \001(\010b\006proto3"
  };
  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
      descriptor, 1614);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "tensorflow_serving/servables/tensorflow/session_bundle_config.proto", &protobuf_RegisterTypes);
  ::protobuf_google_2fprotobuf_2fwrappers_2eproto::AddDescriptors();
  ::protobuf_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto::AddDescriptors();
  ::protobuf_tensorflow_2fcore_2fprotobuf_2fnamed_5ftensor_2eproto::AddDescriptors();
}

void AddDescriptors() {
  static ::google::protobuf::internal::once_flag once;
  ::google::protobuf::internal::call_once(once, AddDescriptorsImpl);
}
// Force AddDescriptors() to be called at dynamic initialization time.
struct StaticDescriptorInitializer {
  StaticDescriptorInitializer() {
    AddDescriptors();
  }
} static_descriptor_initializer;
}  // namespace protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto
namespace tensorflow {
namespace serving {

// ===================================================================

void ModelWarmupOptions::InitAsDefaultInstance() {
  ::tensorflow::serving::_ModelWarmupOptions_default_instance_._instance.get_mutable()->num_request_iterations_ = const_cast< ::google::protobuf::Int32Value*>(
      ::google::protobuf::Int32Value::internal_default_instance());
}
void ModelWarmupOptions::clear_num_request_iterations() {
  if (GetArenaNoVirtual() == NULL && num_request_iterations_ != NULL) {
    delete num_request_iterations_;
  }
  num_request_iterations_ = NULL;
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int ModelWarmupOptions::kNumRequestIterationsFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

ModelWarmupOptions::ModelWarmupOptions()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  ::google::protobuf::internal::InitSCC(
      &protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::scc_info_ModelWarmupOptions.base);
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.ModelWarmupOptions)
}
ModelWarmupOptions::ModelWarmupOptions(const ModelWarmupOptions& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_num_request_iterations()) {
    num_request_iterations_ = new ::google::protobuf::Int32Value(*from.num_request_iterations_);
  } else {
    num_request_iterations_ = NULL;
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.ModelWarmupOptions)
}

void ModelWarmupOptions::SharedCtor() {
  num_request_iterations_ = NULL;
}

ModelWarmupOptions::~ModelWarmupOptions() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.ModelWarmupOptions)
  SharedDtor();
}

void ModelWarmupOptions::SharedDtor() {
  if (this != internal_default_instance()) delete num_request_iterations_;
}

void ModelWarmupOptions::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ::google::protobuf::Descriptor* ModelWarmupOptions::descriptor() {
  ::protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::file_level_metadata[kIndexInFileMessages].descriptor;
}

const ModelWarmupOptions& ModelWarmupOptions::default_instance() {
  ::google::protobuf::internal::InitSCC(&protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::scc_info_ModelWarmupOptions.base);
  return *internal_default_instance();
}


void ModelWarmupOptions::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.ModelWarmupOptions)
  ::google::protobuf::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  if (GetArenaNoVirtual() == NULL && num_request_iterations_ != NULL) {
    delete num_request_iterations_;
  }
  num_request_iterations_ = NULL;
  _internal_metadata_.Clear();
}

bool ModelWarmupOptions::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.ModelWarmupOptions)
  for (;;) {
    ::std::pair<::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // .google.protobuf.Int32Value num_request_iterations = 1;
      case 1: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(10u /* 10 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_num_request_iterations()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.ModelWarmupOptions)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.ModelWarmupOptions)
  return false;
#undef DO_
}

void ModelWarmupOptions::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.ModelWarmupOptions)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .google.protobuf.Int32Value num_request_iterations = 1;
  if (this->has_num_request_iterations()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->_internal_num_request_iterations(), output);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), output);
  }
  // @@protoc_insertion_point(serialize_end:tensorflow.serving.ModelWarmupOptions)
}

::google::protobuf::uint8* ModelWarmupOptions::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.ModelWarmupOptions)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .google.protobuf.Int32Value num_request_iterations = 1;
  if (this->has_num_request_iterations()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        1, this->_internal_num_request_iterations(), deterministic, target);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.ModelWarmupOptions)
  return target;
}

size_t ModelWarmupOptions::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.ModelWarmupOptions)
  size_t total_size = 0;

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()));
  }
  // .google.protobuf.Int32Value num_request_iterations = 1;
  if (this->has_num_request_iterations()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *num_request_iterations_);
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void ModelWarmupOptions::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.ModelWarmupOptions)
  GOOGLE_DCHECK_NE(&from, this);
  const ModelWarmupOptions* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const ModelWarmupOptions>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.ModelWarmupOptions)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.ModelWarmupOptions)
    MergeFrom(*source);
  }
}

void ModelWarmupOptions::MergeFrom(const ModelWarmupOptions& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.ModelWarmupOptions)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  if (from.has_num_request_iterations()) {
    mutable_num_request_iterations()->::google::protobuf::Int32Value::MergeFrom(from.num_request_iterations());
  }
}

void ModelWarmupOptions::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.ModelWarmupOptions)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void ModelWarmupOptions::CopyFrom(const ModelWarmupOptions& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.ModelWarmupOptions)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ModelWarmupOptions::IsInitialized() const {
  return true;
}

void ModelWarmupOptions::Swap(ModelWarmupOptions* other) {
  if (other == this) return;
  InternalSwap(other);
}
void ModelWarmupOptions::InternalSwap(ModelWarmupOptions* other) {
  using std::swap;
  swap(num_request_iterations_, other->num_request_iterations_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
}

::google::protobuf::Metadata ModelWarmupOptions::GetMetadata() const {
  protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::file_level_metadata[kIndexInFileMessages];
}


// ===================================================================

void SessionBundleConfig::InitAsDefaultInstance() {
  ::tensorflow::serving::_SessionBundleConfig_default_instance_._instance.get_mutable()->session_config_ = const_cast< ::tensorflow::ConfigProto*>(
      ::tensorflow::ConfigProto::internal_default_instance());
  ::tensorflow::serving::_SessionBundleConfig_default_instance_._instance.get_mutable()->batching_parameters_ = const_cast< ::tensorflow::serving::BatchingParameters*>(
      ::tensorflow::serving::BatchingParameters::internal_default_instance());
  ::tensorflow::serving::_SessionBundleConfig_default_instance_._instance.get_mutable()->session_run_load_threadpool_index_ = const_cast< ::google::protobuf::Int32Value*>(
      ::google::protobuf::Int32Value::internal_default_instance());
  ::tensorflow::serving::_SessionBundleConfig_default_instance_._instance.get_mutable()->model_warmup_options_ = const_cast< ::tensorflow::serving::ModelWarmupOptions*>(
      ::tensorflow::serving::ModelWarmupOptions::internal_default_instance());
}
void SessionBundleConfig::clear_session_config() {
  if (GetArenaNoVirtual() == NULL && session_config_ != NULL) {
    delete session_config_;
  }
  session_config_ = NULL;
}
void SessionBundleConfig::clear_session_run_load_threadpool_index() {
  if (GetArenaNoVirtual() == NULL && session_run_load_threadpool_index_ != NULL) {
    delete session_run_load_threadpool_index_;
  }
  session_run_load_threadpool_index_ = NULL;
}
void SessionBundleConfig::clear_experimental_fixed_input_tensors() {
  experimental_fixed_input_tensors_.Clear();
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int SessionBundleConfig::kSessionTargetFieldNumber;
const int SessionBundleConfig::kSessionConfigFieldNumber;
const int SessionBundleConfig::kBatchingParametersFieldNumber;
const int SessionBundleConfig::kSessionRunLoadThreadpoolIndexFieldNumber;
const int SessionBundleConfig::kExperimentalTransientRamBytesDuringLoadFieldNumber;
const int SessionBundleConfig::kSavedModelTagsFieldNumber;
const int SessionBundleConfig::kExperimentalFixedInputTensorsFieldNumber;
const int SessionBundleConfig::kEnableModelWarmupFieldNumber;
const int SessionBundleConfig::kModelWarmupOptionsFieldNumber;
const int SessionBundleConfig::kEnableSessionMetadataFieldNumber;
const int SessionBundleConfig::kRemoveUnusedFieldsFromBundleMetagraphFieldNumber;
const int SessionBundleConfig::kPreferTfliteModelFieldNumber;
const int SessionBundleConfig::kResourceEstimationUsesValidationResultFieldNumber;
const int SessionBundleConfig::kNumTfliteInterpretersFieldNumber;
const int SessionBundleConfig::kNumTfliteInterpretersPerPoolFieldNumber;
const int SessionBundleConfig::kNumTflitePoolsFieldNumber;
const int SessionBundleConfig::kWrapSessionWithNoThreadingParamsFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

SessionBundleConfig::SessionBundleConfig()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  ::google::protobuf::internal::InitSCC(
      &protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::scc_info_SessionBundleConfig.base);
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.SessionBundleConfig)
}
SessionBundleConfig::SessionBundleConfig(const SessionBundleConfig& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      saved_model_tags_(from.saved_model_tags_),
      experimental_fixed_input_tensors_(from.experimental_fixed_input_tensors_) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  session_target_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (from.session_target().size() > 0) {
    session_target_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.session_target_);
  }
  if (from.has_session_config()) {
    session_config_ = new ::tensorflow::ConfigProto(*from.session_config_);
  } else {
    session_config_ = NULL;
  }
  if (from.has_batching_parameters()) {
    batching_parameters_ = new ::tensorflow::serving::BatchingParameters(*from.batching_parameters_);
  } else {
    batching_parameters_ = NULL;
  }
  if (from.has_session_run_load_threadpool_index()) {
    session_run_load_threadpool_index_ = new ::google::protobuf::Int32Value(*from.session_run_load_threadpool_index_);
  } else {
    session_run_load_threadpool_index_ = NULL;
  }
  if (from.has_model_warmup_options()) {
    model_warmup_options_ = new ::tensorflow::serving::ModelWarmupOptions(*from.model_warmup_options_);
  } else {
    model_warmup_options_ = NULL;
  }
  ::memcpy(&experimental_transient_ram_bytes_during_load_, &from.experimental_transient_ram_bytes_during_load_,
    static_cast<size_t>(reinterpret_cast<char*>(&wrap_session_with_no_threading_params_) -
    reinterpret_cast<char*>(&experimental_transient_ram_bytes_during_load_)) + sizeof(wrap_session_with_no_threading_params_));
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.SessionBundleConfig)
}

void SessionBundleConfig::SharedCtor() {
  session_target_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  ::memset(&session_config_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&wrap_session_with_no_threading_params_) -
      reinterpret_cast<char*>(&session_config_)) + sizeof(wrap_session_with_no_threading_params_));
}

SessionBundleConfig::~SessionBundleConfig() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.SessionBundleConfig)
  SharedDtor();
}

void SessionBundleConfig::SharedDtor() {
  session_target_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (this != internal_default_instance()) delete session_config_;
  if (this != internal_default_instance()) delete batching_parameters_;
  if (this != internal_default_instance()) delete session_run_load_threadpool_index_;
  if (this != internal_default_instance()) delete model_warmup_options_;
}

void SessionBundleConfig::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ::google::protobuf::Descriptor* SessionBundleConfig::descriptor() {
  ::protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::file_level_metadata[kIndexInFileMessages].descriptor;
}

const SessionBundleConfig& SessionBundleConfig::default_instance() {
  ::google::protobuf::internal::InitSCC(&protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::scc_info_SessionBundleConfig.base);
  return *internal_default_instance();
}


void SessionBundleConfig::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.SessionBundleConfig)
  ::google::protobuf::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  saved_model_tags_.Clear();
  experimental_fixed_input_tensors_.Clear();
  session_target_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (GetArenaNoVirtual() == NULL && session_config_ != NULL) {
    delete session_config_;
  }
  session_config_ = NULL;
  if (GetArenaNoVirtual() == NULL && batching_parameters_ != NULL) {
    delete batching_parameters_;
  }
  batching_parameters_ = NULL;
  if (GetArenaNoVirtual() == NULL && session_run_load_threadpool_index_ != NULL) {
    delete session_run_load_threadpool_index_;
  }
  session_run_load_threadpool_index_ = NULL;
  if (GetArenaNoVirtual() == NULL && model_warmup_options_ != NULL) {
    delete model_warmup_options_;
  }
  model_warmup_options_ = NULL;
  ::memset(&experimental_transient_ram_bytes_during_load_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&wrap_session_with_no_threading_params_) -
      reinterpret_cast<char*>(&experimental_transient_ram_bytes_during_load_)) + sizeof(wrap_session_with_no_threading_params_));
  _internal_metadata_.Clear();
}

bool SessionBundleConfig::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.SessionBundleConfig)
  for (;;) {
    ::std::pair<::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(16383u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // string session_target = 1;
      case 1: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(10u /* 10 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_session_target()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->session_target().data(), static_cast<int>(this->session_target().length()),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.serving.SessionBundleConfig.session_target"));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.ConfigProto session_config = 2;
      case 2: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(18u /* 18 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_session_config()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.BatchingParameters batching_parameters = 3;
      case 3: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(26u /* 26 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_batching_parameters()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .google.protobuf.Int32Value session_run_load_threadpool_index = 4;
      case 4: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(34u /* 34 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_session_run_load_threadpool_index()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // uint64 experimental_transient_ram_bytes_during_load = 5;
      case 5: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(40u /* 40 & 0xFF */)) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::uint64, ::google::protobuf::internal::WireFormatLite::TYPE_UINT64>(
                 input, &experimental_transient_ram_bytes_during_load_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // repeated string saved_model_tags = 6;
      case 6: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(50u /* 50 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->add_saved_model_tags()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->saved_model_tags(this->saved_model_tags_size() - 1).data(),
            static_cast<int>(this->saved_model_tags(this->saved_model_tags_size() - 1).length()),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.serving.SessionBundleConfig.saved_model_tags"));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // repeated .tensorflow.NamedTensorProto experimental_fixed_input_tensors = 778;
      case 778: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(82u /* 6226 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
                input, add_experimental_fixed_input_tensors()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // bool enable_model_warmup = 779;
      case 779: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(88u /* 6232 & 0xFF */)) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &enable_model_warmup_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.ModelWarmupOptions model_warmup_options = 780;
      case 780: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(98u /* 6242 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_model_warmup_options()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // bool enable_session_metadata = 781;
      case 781: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(104u /* 6248 & 0xFF */)) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &enable_session_metadata_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // bool remove_unused_fields_from_bundle_metagraph = 782;
      case 782: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(112u /* 6256 & 0xFF */)) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &remove_unused_fields_from_bundle_metagraph_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // bool prefer_tflite_model = 783;
      case 783: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(120u /* 6264 & 0xFF */)) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &prefer_tflite_model_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // bool resource_estimation_uses_validation_result = 784;
      case 784: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(128u /* 6272 & 0xFF */)) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &resource_estimation_uses_validation_result_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // int32 num_tflite_interpreters = 785 [deprecated = true];
      case 785: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(136u /* 6280 & 0xFF */)) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &num_tflite_interpreters_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // int32 num_tflite_interpreters_per_pool = 786;
      case 786: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(144u /* 6288 & 0xFF */)) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &num_tflite_interpreters_per_pool_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // int32 num_tflite_pools = 787;
      case 787: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(152u /* 6296 & 0xFF */)) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &num_tflite_pools_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // bool wrap_session_with_no_threading_params = 788;
      case 788: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(160u /* 6304 & 0xFF */)) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &wrap_session_with_no_threading_params_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.SessionBundleConfig)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.SessionBundleConfig)
  return false;
#undef DO_
}

void SessionBundleConfig::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.SessionBundleConfig)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // string session_target = 1;
  if (this->session_target().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->session_target().data(), static_cast<int>(this->session_target().length()),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.SessionBundleConfig.session_target");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      1, this->session_target(), output);
  }

  // .tensorflow.ConfigProto session_config = 2;
  if (this->has_session_config()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, this->_internal_session_config(), output);
  }

  // .tensorflow.serving.BatchingParameters batching_parameters = 3;
  if (this->has_batching_parameters()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      3, this->_internal_batching_parameters(), output);
  }

  // .google.protobuf.Int32Value session_run_load_threadpool_index = 4;
  if (this->has_session_run_load_threadpool_index()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      4, this->_internal_session_run_load_threadpool_index(), output);
  }

  // uint64 experimental_transient_ram_bytes_during_load = 5;
  if (this->experimental_transient_ram_bytes_during_load() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteUInt64(5, this->experimental_transient_ram_bytes_during_load(), output);
  }

  // repeated string saved_model_tags = 6;
  for (int i = 0, n = this->saved_model_tags_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->saved_model_tags(i).data(), static_cast<int>(this->saved_model_tags(i).length()),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.SessionBundleConfig.saved_model_tags");
    ::google::protobuf::internal::WireFormatLite::WriteString(
      6, this->saved_model_tags(i), output);
  }

  // repeated .tensorflow.NamedTensorProto experimental_fixed_input_tensors = 778;
  for (unsigned int i = 0,
      n = static_cast<unsigned int>(this->experimental_fixed_input_tensors_size()); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      778,
      this->experimental_fixed_input_tensors(static_cast<int>(i)),
      output);
  }

  // bool enable_model_warmup = 779;
  if (this->enable_model_warmup() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(779, this->enable_model_warmup(), output);
  }

  // .tensorflow.serving.ModelWarmupOptions model_warmup_options = 780;
  if (this->has_model_warmup_options()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      780, this->_internal_model_warmup_options(), output);
  }

  // bool enable_session_metadata = 781;
  if (this->enable_session_metadata() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(781, this->enable_session_metadata(), output);
  }

  // bool remove_unused_fields_from_bundle_metagraph = 782;
  if (this->remove_unused_fields_from_bundle_metagraph() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(782, this->remove_unused_fields_from_bundle_metagraph(), output);
  }

  // bool prefer_tflite_model = 783;
  if (this->prefer_tflite_model() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(783, this->prefer_tflite_model(), output);
  }

  // bool resource_estimation_uses_validation_result = 784;
  if (this->resource_estimation_uses_validation_result() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(784, this->resource_estimation_uses_validation_result(), output);
  }

  // int32 num_tflite_interpreters = 785 [deprecated = true];
  if (this->num_tflite_interpreters() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(785, this->num_tflite_interpreters(), output);
  }

  // int32 num_tflite_interpreters_per_pool = 786;
  if (this->num_tflite_interpreters_per_pool() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(786, this->num_tflite_interpreters_per_pool(), output);
  }

  // int32 num_tflite_pools = 787;
  if (this->num_tflite_pools() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(787, this->num_tflite_pools(), output);
  }

  // bool wrap_session_with_no_threading_params = 788;
  if (this->wrap_session_with_no_threading_params() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(788, this->wrap_session_with_no_threading_params(), output);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), output);
  }
  // @@protoc_insertion_point(serialize_end:tensorflow.serving.SessionBundleConfig)
}

::google::protobuf::uint8* SessionBundleConfig::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.SessionBundleConfig)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // string session_target = 1;
  if (this->session_target().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->session_target().data(), static_cast<int>(this->session_target().length()),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.SessionBundleConfig.session_target");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        1, this->session_target(), target);
  }

  // .tensorflow.ConfigProto session_config = 2;
  if (this->has_session_config()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        2, this->_internal_session_config(), deterministic, target);
  }

  // .tensorflow.serving.BatchingParameters batching_parameters = 3;
  if (this->has_batching_parameters()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        3, this->_internal_batching_parameters(), deterministic, target);
  }

  // .google.protobuf.Int32Value session_run_load_threadpool_index = 4;
  if (this->has_session_run_load_threadpool_index()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        4, this->_internal_session_run_load_threadpool_index(), deterministic, target);
  }

  // uint64 experimental_transient_ram_bytes_during_load = 5;
  if (this->experimental_transient_ram_bytes_during_load() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteUInt64ToArray(5, this->experimental_transient_ram_bytes_during_load(), target);
  }

  // repeated string saved_model_tags = 6;
  for (int i = 0, n = this->saved_model_tags_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->saved_model_tags(i).data(), static_cast<int>(this->saved_model_tags(i).length()),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.SessionBundleConfig.saved_model_tags");
    target = ::google::protobuf::internal::WireFormatLite::
      WriteStringToArray(6, this->saved_model_tags(i), target);
  }

  // repeated .tensorflow.NamedTensorProto experimental_fixed_input_tensors = 778;
  for (unsigned int i = 0,
      n = static_cast<unsigned int>(this->experimental_fixed_input_tensors_size()); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        778, this->experimental_fixed_input_tensors(static_cast<int>(i)), deterministic, target);
  }

  // bool enable_model_warmup = 779;
  if (this->enable_model_warmup() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(779, this->enable_model_warmup(), target);
  }

  // .tensorflow.serving.ModelWarmupOptions model_warmup_options = 780;
  if (this->has_model_warmup_options()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        780, this->_internal_model_warmup_options(), deterministic, target);
  }

  // bool enable_session_metadata = 781;
  if (this->enable_session_metadata() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(781, this->enable_session_metadata(), target);
  }

  // bool remove_unused_fields_from_bundle_metagraph = 782;
  if (this->remove_unused_fields_from_bundle_metagraph() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(782, this->remove_unused_fields_from_bundle_metagraph(), target);
  }

  // bool prefer_tflite_model = 783;
  if (this->prefer_tflite_model() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(783, this->prefer_tflite_model(), target);
  }

  // bool resource_estimation_uses_validation_result = 784;
  if (this->resource_estimation_uses_validation_result() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(784, this->resource_estimation_uses_validation_result(), target);
  }

  // int32 num_tflite_interpreters = 785 [deprecated = true];
  if (this->num_tflite_interpreters() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(785, this->num_tflite_interpreters(), target);
  }

  // int32 num_tflite_interpreters_per_pool = 786;
  if (this->num_tflite_interpreters_per_pool() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(786, this->num_tflite_interpreters_per_pool(), target);
  }

  // int32 num_tflite_pools = 787;
  if (this->num_tflite_pools() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(787, this->num_tflite_pools(), target);
  }

  // bool wrap_session_with_no_threading_params = 788;
  if (this->wrap_session_with_no_threading_params() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(788, this->wrap_session_with_no_threading_params(), target);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.SessionBundleConfig)
  return target;
}

size_t SessionBundleConfig::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.SessionBundleConfig)
  size_t total_size = 0;

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()));
  }
  // repeated string saved_model_tags = 6;
  total_size += 1 *
      ::google::protobuf::internal::FromIntSize(this->saved_model_tags_size());
  for (int i = 0, n = this->saved_model_tags_size(); i < n; i++) {
    total_size += ::google::protobuf::internal::WireFormatLite::StringSize(
      this->saved_model_tags(i));
  }

  // repeated .tensorflow.NamedTensorProto experimental_fixed_input_tensors = 778;
  {
    unsigned int count = static_cast<unsigned int>(this->experimental_fixed_input_tensors_size());
    total_size += 2UL * count;
    for (unsigned int i = 0; i < count; i++) {
      total_size +=
        ::google::protobuf::internal::WireFormatLite::MessageSize(
          this->experimental_fixed_input_tensors(static_cast<int>(i)));
    }
  }

  // string session_target = 1;
  if (this->session_target().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->session_target());
  }

  // .tensorflow.ConfigProto session_config = 2;
  if (this->has_session_config()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *session_config_);
  }

  // .tensorflow.serving.BatchingParameters batching_parameters = 3;
  if (this->has_batching_parameters()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *batching_parameters_);
  }

  // .google.protobuf.Int32Value session_run_load_threadpool_index = 4;
  if (this->has_session_run_load_threadpool_index()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *session_run_load_threadpool_index_);
  }

  // .tensorflow.serving.ModelWarmupOptions model_warmup_options = 780;
  if (this->has_model_warmup_options()) {
    total_size += 2 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *model_warmup_options_);
  }

  // uint64 experimental_transient_ram_bytes_during_load = 5;
  if (this->experimental_transient_ram_bytes_during_load() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::UInt64Size(
        this->experimental_transient_ram_bytes_during_load());
  }

  // int32 num_tflite_pools = 787;
  if (this->num_tflite_pools() != 0) {
    total_size += 2 +
      ::google::protobuf::internal::WireFormatLite::Int32Size(
        this->num_tflite_pools());
  }

  // bool enable_model_warmup = 779;
  if (this->enable_model_warmup() != 0) {
    total_size += 2 + 1;
  }

  // bool enable_session_metadata = 781;
  if (this->enable_session_metadata() != 0) {
    total_size += 2 + 1;
  }

  // bool remove_unused_fields_from_bundle_metagraph = 782;
  if (this->remove_unused_fields_from_bundle_metagraph() != 0) {
    total_size += 2 + 1;
  }

  // bool prefer_tflite_model = 783;
  if (this->prefer_tflite_model() != 0) {
    total_size += 2 + 1;
  }

  // int32 num_tflite_interpreters = 785 [deprecated = true];
  if (this->num_tflite_interpreters() != 0) {
    total_size += 2 +
      ::google::protobuf::internal::WireFormatLite::Int32Size(
        this->num_tflite_interpreters());
  }

  // int32 num_tflite_interpreters_per_pool = 786;
  if (this->num_tflite_interpreters_per_pool() != 0) {
    total_size += 2 +
      ::google::protobuf::internal::WireFormatLite::Int32Size(
        this->num_tflite_interpreters_per_pool());
  }

  // bool resource_estimation_uses_validation_result = 784;
  if (this->resource_estimation_uses_validation_result() != 0) {
    total_size += 2 + 1;
  }

  // bool wrap_session_with_no_threading_params = 788;
  if (this->wrap_session_with_no_threading_params() != 0) {
    total_size += 2 + 1;
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void SessionBundleConfig::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.SessionBundleConfig)
  GOOGLE_DCHECK_NE(&from, this);
  const SessionBundleConfig* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const SessionBundleConfig>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.SessionBundleConfig)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.SessionBundleConfig)
    MergeFrom(*source);
  }
}

void SessionBundleConfig::MergeFrom(const SessionBundleConfig& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.SessionBundleConfig)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  saved_model_tags_.MergeFrom(from.saved_model_tags_);
  experimental_fixed_input_tensors_.MergeFrom(from.experimental_fixed_input_tensors_);
  if (from.session_target().size() > 0) {

    session_target_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.session_target_);
  }
  if (from.has_session_config()) {
    mutable_session_config()->::tensorflow::ConfigProto::MergeFrom(from.session_config());
  }
  if (from.has_batching_parameters()) {
    mutable_batching_parameters()->::tensorflow::serving::BatchingParameters::MergeFrom(from.batching_parameters());
  }
  if (from.has_session_run_load_threadpool_index()) {
    mutable_session_run_load_threadpool_index()->::google::protobuf::Int32Value::MergeFrom(from.session_run_load_threadpool_index());
  }
  if (from.has_model_warmup_options()) {
    mutable_model_warmup_options()->::tensorflow::serving::ModelWarmupOptions::MergeFrom(from.model_warmup_options());
  }
  if (from.experimental_transient_ram_bytes_during_load() != 0) {
    set_experimental_transient_ram_bytes_during_load(from.experimental_transient_ram_bytes_during_load());
  }
  if (from.num_tflite_pools() != 0) {
    set_num_tflite_pools(from.num_tflite_pools());
  }
  if (from.enable_model_warmup() != 0) {
    set_enable_model_warmup(from.enable_model_warmup());
  }
  if (from.enable_session_metadata() != 0) {
    set_enable_session_metadata(from.enable_session_metadata());
  }
  if (from.remove_unused_fields_from_bundle_metagraph() != 0) {
    set_remove_unused_fields_from_bundle_metagraph(from.remove_unused_fields_from_bundle_metagraph());
  }
  if (from.prefer_tflite_model() != 0) {
    set_prefer_tflite_model(from.prefer_tflite_model());
  }
  if (from.num_tflite_interpreters() != 0) {
    set_num_tflite_interpreters(from.num_tflite_interpreters());
  }
  if (from.num_tflite_interpreters_per_pool() != 0) {
    set_num_tflite_interpreters_per_pool(from.num_tflite_interpreters_per_pool());
  }
  if (from.resource_estimation_uses_validation_result() != 0) {
    set_resource_estimation_uses_validation_result(from.resource_estimation_uses_validation_result());
  }
  if (from.wrap_session_with_no_threading_params() != 0) {
    set_wrap_session_with_no_threading_params(from.wrap_session_with_no_threading_params());
  }
}

void SessionBundleConfig::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.SessionBundleConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void SessionBundleConfig::CopyFrom(const SessionBundleConfig& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.SessionBundleConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool SessionBundleConfig::IsInitialized() const {
  return true;
}

void SessionBundleConfig::Swap(SessionBundleConfig* other) {
  if (other == this) return;
  InternalSwap(other);
}
void SessionBundleConfig::InternalSwap(SessionBundleConfig* other) {
  using std::swap;
  saved_model_tags_.InternalSwap(CastToBase(&other->saved_model_tags_));
  CastToBase(&experimental_fixed_input_tensors_)->InternalSwap(CastToBase(&other->experimental_fixed_input_tensors_));
  session_target_.Swap(&other->session_target_, &::google::protobuf::internal::GetEmptyStringAlreadyInited(),
    GetArenaNoVirtual());
  swap(session_config_, other->session_config_);
  swap(batching_parameters_, other->batching_parameters_);
  swap(session_run_load_threadpool_index_, other->session_run_load_threadpool_index_);
  swap(model_warmup_options_, other->model_warmup_options_);
  swap(experimental_transient_ram_bytes_during_load_, other->experimental_transient_ram_bytes_during_load_);
  swap(num_tflite_pools_, other->num_tflite_pools_);
  swap(enable_model_warmup_, other->enable_model_warmup_);
  swap(enable_session_metadata_, other->enable_session_metadata_);
  swap(remove_unused_fields_from_bundle_metagraph_, other->remove_unused_fields_from_bundle_metagraph_);
  swap(prefer_tflite_model_, other->prefer_tflite_model_);
  swap(num_tflite_interpreters_, other->num_tflite_interpreters_);
  swap(num_tflite_interpreters_per_pool_, other->num_tflite_interpreters_per_pool_);
  swap(resource_estimation_uses_validation_result_, other->resource_estimation_uses_validation_result_);
  swap(wrap_session_with_no_threading_params_, other->wrap_session_with_no_threading_params_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
}

::google::protobuf::Metadata SessionBundleConfig::GetMetadata() const {
  protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::file_level_metadata[kIndexInFileMessages];
}


// ===================================================================

void BatchingParameters::InitAsDefaultInstance() {
  ::tensorflow::serving::_BatchingParameters_default_instance_._instance.get_mutable()->max_batch_size_ = const_cast< ::google::protobuf::Int64Value*>(
      ::google::protobuf::Int64Value::internal_default_instance());
  ::tensorflow::serving::_BatchingParameters_default_instance_._instance.get_mutable()->batch_timeout_micros_ = const_cast< ::google::protobuf::Int64Value*>(
      ::google::protobuf::Int64Value::internal_default_instance());
  ::tensorflow::serving::_BatchingParameters_default_instance_._instance.get_mutable()->max_enqueued_batches_ = const_cast< ::google::protobuf::Int64Value*>(
      ::google::protobuf::Int64Value::internal_default_instance());
  ::tensorflow::serving::_BatchingParameters_default_instance_._instance.get_mutable()->num_batch_threads_ = const_cast< ::google::protobuf::Int64Value*>(
      ::google::protobuf::Int64Value::internal_default_instance());
  ::tensorflow::serving::_BatchingParameters_default_instance_._instance.get_mutable()->thread_pool_name_ = const_cast< ::google::protobuf::StringValue*>(
      ::google::protobuf::StringValue::internal_default_instance());
  ::tensorflow::serving::_BatchingParameters_default_instance_._instance.get_mutable()->enable_large_batch_splitting_ = const_cast< ::google::protobuf::BoolValue*>(
      ::google::protobuf::BoolValue::internal_default_instance());
  ::tensorflow::serving::_BatchingParameters_default_instance_._instance.get_mutable()->max_execution_batch_size_ = const_cast< ::google::protobuf::Int64Value*>(
      ::google::protobuf::Int64Value::internal_default_instance());
}
void BatchingParameters::clear_max_batch_size() {
  if (GetArenaNoVirtual() == NULL && max_batch_size_ != NULL) {
    delete max_batch_size_;
  }
  max_batch_size_ = NULL;
}
void BatchingParameters::clear_batch_timeout_micros() {
  if (GetArenaNoVirtual() == NULL && batch_timeout_micros_ != NULL) {
    delete batch_timeout_micros_;
  }
  batch_timeout_micros_ = NULL;
}
void BatchingParameters::clear_max_enqueued_batches() {
  if (GetArenaNoVirtual() == NULL && max_enqueued_batches_ != NULL) {
    delete max_enqueued_batches_;
  }
  max_enqueued_batches_ = NULL;
}
void BatchingParameters::clear_num_batch_threads() {
  if (GetArenaNoVirtual() == NULL && num_batch_threads_ != NULL) {
    delete num_batch_threads_;
  }
  num_batch_threads_ = NULL;
}
void BatchingParameters::clear_thread_pool_name() {
  if (GetArenaNoVirtual() == NULL && thread_pool_name_ != NULL) {
    delete thread_pool_name_;
  }
  thread_pool_name_ = NULL;
}
void BatchingParameters::clear_enable_large_batch_splitting() {
  if (GetArenaNoVirtual() == NULL && enable_large_batch_splitting_ != NULL) {
    delete enable_large_batch_splitting_;
  }
  enable_large_batch_splitting_ = NULL;
}
void BatchingParameters::clear_max_execution_batch_size() {
  if (GetArenaNoVirtual() == NULL && max_execution_batch_size_ != NULL) {
    delete max_execution_batch_size_;
  }
  max_execution_batch_size_ = NULL;
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int BatchingParameters::kMaxBatchSizeFieldNumber;
const int BatchingParameters::kBatchTimeoutMicrosFieldNumber;
const int BatchingParameters::kMaxEnqueuedBatchesFieldNumber;
const int BatchingParameters::kNumBatchThreadsFieldNumber;
const int BatchingParameters::kThreadPoolNameFieldNumber;
const int BatchingParameters::kEnableLargeBatchSplittingFieldNumber;
const int BatchingParameters::kMaxExecutionBatchSizeFieldNumber;
const int BatchingParameters::kAllowedBatchSizesFieldNumber;
const int BatchingParameters::kPadVariableLengthInputsFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

BatchingParameters::BatchingParameters()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  ::google::protobuf::internal::InitSCC(
      &protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::scc_info_BatchingParameters.base);
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.BatchingParameters)
}
BatchingParameters::BatchingParameters(const BatchingParameters& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      allowed_batch_sizes_(from.allowed_batch_sizes_) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_max_batch_size()) {
    max_batch_size_ = new ::google::protobuf::Int64Value(*from.max_batch_size_);
  } else {
    max_batch_size_ = NULL;
  }
  if (from.has_batch_timeout_micros()) {
    batch_timeout_micros_ = new ::google::protobuf::Int64Value(*from.batch_timeout_micros_);
  } else {
    batch_timeout_micros_ = NULL;
  }
  if (from.has_max_enqueued_batches()) {
    max_enqueued_batches_ = new ::google::protobuf::Int64Value(*from.max_enqueued_batches_);
  } else {
    max_enqueued_batches_ = NULL;
  }
  if (from.has_num_batch_threads()) {
    num_batch_threads_ = new ::google::protobuf::Int64Value(*from.num_batch_threads_);
  } else {
    num_batch_threads_ = NULL;
  }
  if (from.has_thread_pool_name()) {
    thread_pool_name_ = new ::google::protobuf::StringValue(*from.thread_pool_name_);
  } else {
    thread_pool_name_ = NULL;
  }
  if (from.has_enable_large_batch_splitting()) {
    enable_large_batch_splitting_ = new ::google::protobuf::BoolValue(*from.enable_large_batch_splitting_);
  } else {
    enable_large_batch_splitting_ = NULL;
  }
  if (from.has_max_execution_batch_size()) {
    max_execution_batch_size_ = new ::google::protobuf::Int64Value(*from.max_execution_batch_size_);
  } else {
    max_execution_batch_size_ = NULL;
  }
  pad_variable_length_inputs_ = from.pad_variable_length_inputs_;
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.BatchingParameters)
}

void BatchingParameters::SharedCtor() {
  ::memset(&max_batch_size_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&pad_variable_length_inputs_) -
      reinterpret_cast<char*>(&max_batch_size_)) + sizeof(pad_variable_length_inputs_));
}

BatchingParameters::~BatchingParameters() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.BatchingParameters)
  SharedDtor();
}

void BatchingParameters::SharedDtor() {
  if (this != internal_default_instance()) delete max_batch_size_;
  if (this != internal_default_instance()) delete batch_timeout_micros_;
  if (this != internal_default_instance()) delete max_enqueued_batches_;
  if (this != internal_default_instance()) delete num_batch_threads_;
  if (this != internal_default_instance()) delete thread_pool_name_;
  if (this != internal_default_instance()) delete enable_large_batch_splitting_;
  if (this != internal_default_instance()) delete max_execution_batch_size_;
}

void BatchingParameters::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ::google::protobuf::Descriptor* BatchingParameters::descriptor() {
  ::protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::file_level_metadata[kIndexInFileMessages].descriptor;
}

const BatchingParameters& BatchingParameters::default_instance() {
  ::google::protobuf::internal::InitSCC(&protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::scc_info_BatchingParameters.base);
  return *internal_default_instance();
}


void BatchingParameters::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.BatchingParameters)
  ::google::protobuf::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  allowed_batch_sizes_.Clear();
  if (GetArenaNoVirtual() == NULL && max_batch_size_ != NULL) {
    delete max_batch_size_;
  }
  max_batch_size_ = NULL;
  if (GetArenaNoVirtual() == NULL && batch_timeout_micros_ != NULL) {
    delete batch_timeout_micros_;
  }
  batch_timeout_micros_ = NULL;
  if (GetArenaNoVirtual() == NULL && max_enqueued_batches_ != NULL) {
    delete max_enqueued_batches_;
  }
  max_enqueued_batches_ = NULL;
  if (GetArenaNoVirtual() == NULL && num_batch_threads_ != NULL) {
    delete num_batch_threads_;
  }
  num_batch_threads_ = NULL;
  if (GetArenaNoVirtual() == NULL && thread_pool_name_ != NULL) {
    delete thread_pool_name_;
  }
  thread_pool_name_ = NULL;
  if (GetArenaNoVirtual() == NULL && enable_large_batch_splitting_ != NULL) {
    delete enable_large_batch_splitting_;
  }
  enable_large_batch_splitting_ = NULL;
  if (GetArenaNoVirtual() == NULL && max_execution_batch_size_ != NULL) {
    delete max_execution_batch_size_;
  }
  max_execution_batch_size_ = NULL;
  pad_variable_length_inputs_ = false;
  _internal_metadata_.Clear();
}

bool BatchingParameters::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.BatchingParameters)
  for (;;) {
    ::std::pair<::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // .google.protobuf.Int64Value max_batch_size = 1;
      case 1: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(10u /* 10 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_max_batch_size()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .google.protobuf.Int64Value batch_timeout_micros = 2;
      case 2: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(18u /* 18 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_batch_timeout_micros()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .google.protobuf.Int64Value max_enqueued_batches = 3;
      case 3: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(26u /* 26 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_max_enqueued_batches()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .google.protobuf.Int64Value num_batch_threads = 4;
      case 4: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(34u /* 34 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_num_batch_threads()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .google.protobuf.StringValue thread_pool_name = 5;
      case 5: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(42u /* 42 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_thread_pool_name()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // repeated int64 allowed_batch_sizes = 6;
      case 6: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(50u /* 50 & 0xFF */)) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPackedPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, this->mutable_allowed_batch_sizes())));
        } else if (
            static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(48u /* 48 & 0xFF */)) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadRepeatedPrimitiveNoInline<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 1, 50u, input, this->mutable_allowed_batch_sizes())));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // bool pad_variable_length_inputs = 7;
      case 7: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(56u /* 56 & 0xFF */)) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &pad_variable_length_inputs_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .google.protobuf.BoolValue enable_large_batch_splitting = 8;
      case 8: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(66u /* 66 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_enable_large_batch_splitting()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .google.protobuf.Int64Value max_execution_batch_size = 9;
      case 9: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(74u /* 74 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_max_execution_batch_size()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.BatchingParameters)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.BatchingParameters)
  return false;
#undef DO_
}

void BatchingParameters::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.BatchingParameters)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .google.protobuf.Int64Value max_batch_size = 1;
  if (this->has_max_batch_size()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->_internal_max_batch_size(), output);
  }

  // .google.protobuf.Int64Value batch_timeout_micros = 2;
  if (this->has_batch_timeout_micros()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, this->_internal_batch_timeout_micros(), output);
  }

  // .google.protobuf.Int64Value max_enqueued_batches = 3;
  if (this->has_max_enqueued_batches()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      3, this->_internal_max_enqueued_batches(), output);
  }

  // .google.protobuf.Int64Value num_batch_threads = 4;
  if (this->has_num_batch_threads()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      4, this->_internal_num_batch_threads(), output);
  }

  // .google.protobuf.StringValue thread_pool_name = 5;
  if (this->has_thread_pool_name()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      5, this->_internal_thread_pool_name(), output);
  }

  // repeated int64 allowed_batch_sizes = 6;
  if (this->allowed_batch_sizes_size() > 0) {
    ::google::protobuf::internal::WireFormatLite::WriteTag(6, ::google::protobuf::internal::WireFormatLite::WIRETYPE_LENGTH_DELIMITED, output);
    output->WriteVarint32(static_cast< ::google::protobuf::uint32>(
        _allowed_batch_sizes_cached_byte_size_));
  }
  for (int i = 0, n = this->allowed_batch_sizes_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64NoTag(
      this->allowed_batch_sizes(i), output);
  }

  // bool pad_variable_length_inputs = 7;
  if (this->pad_variable_length_inputs() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(7, this->pad_variable_length_inputs(), output);
  }

  // .google.protobuf.BoolValue enable_large_batch_splitting = 8;
  if (this->has_enable_large_batch_splitting()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      8, this->_internal_enable_large_batch_splitting(), output);
  }

  // .google.protobuf.Int64Value max_execution_batch_size = 9;
  if (this->has_max_execution_batch_size()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      9, this->_internal_max_execution_batch_size(), output);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), output);
  }
  // @@protoc_insertion_point(serialize_end:tensorflow.serving.BatchingParameters)
}

::google::protobuf::uint8* BatchingParameters::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.BatchingParameters)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .google.protobuf.Int64Value max_batch_size = 1;
  if (this->has_max_batch_size()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        1, this->_internal_max_batch_size(), deterministic, target);
  }

  // .google.protobuf.Int64Value batch_timeout_micros = 2;
  if (this->has_batch_timeout_micros()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        2, this->_internal_batch_timeout_micros(), deterministic, target);
  }

  // .google.protobuf.Int64Value max_enqueued_batches = 3;
  if (this->has_max_enqueued_batches()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        3, this->_internal_max_enqueued_batches(), deterministic, target);
  }

  // .google.protobuf.Int64Value num_batch_threads = 4;
  if (this->has_num_batch_threads()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        4, this->_internal_num_batch_threads(), deterministic, target);
  }

  // .google.protobuf.StringValue thread_pool_name = 5;
  if (this->has_thread_pool_name()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        5, this->_internal_thread_pool_name(), deterministic, target);
  }

  // repeated int64 allowed_batch_sizes = 6;
  if (this->allowed_batch_sizes_size() > 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteTagToArray(
      6,
      ::google::protobuf::internal::WireFormatLite::WIRETYPE_LENGTH_DELIMITED,
      target);
    target = ::google::protobuf::io::CodedOutputStream::WriteVarint32ToArray(
        static_cast< ::google::protobuf::int32>(
            _allowed_batch_sizes_cached_byte_size_), target);
    target = ::google::protobuf::internal::WireFormatLite::
      WriteInt64NoTagToArray(this->allowed_batch_sizes_, target);
  }

  // bool pad_variable_length_inputs = 7;
  if (this->pad_variable_length_inputs() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(7, this->pad_variable_length_inputs(), target);
  }

  // .google.protobuf.BoolValue enable_large_batch_splitting = 8;
  if (this->has_enable_large_batch_splitting()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        8, this->_internal_enable_large_batch_splitting(), deterministic, target);
  }

  // .google.protobuf.Int64Value max_execution_batch_size = 9;
  if (this->has_max_execution_batch_size()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        9, this->_internal_max_execution_batch_size(), deterministic, target);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.BatchingParameters)
  return target;
}

size_t BatchingParameters::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.BatchingParameters)
  size_t total_size = 0;

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()));
  }
  // repeated int64 allowed_batch_sizes = 6;
  {
    size_t data_size = ::google::protobuf::internal::WireFormatLite::
      Int64Size(this->allowed_batch_sizes_);
    if (data_size > 0) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(
            static_cast< ::google::protobuf::int32>(data_size));
    }
    int cached_size = ::google::protobuf::internal::ToCachedSize(data_size);
    GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
    _allowed_batch_sizes_cached_byte_size_ = cached_size;
    GOOGLE_SAFE_CONCURRENT_WRITES_END();
    total_size += data_size;
  }

  // .google.protobuf.Int64Value max_batch_size = 1;
  if (this->has_max_batch_size()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *max_batch_size_);
  }

  // .google.protobuf.Int64Value batch_timeout_micros = 2;
  if (this->has_batch_timeout_micros()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *batch_timeout_micros_);
  }

  // .google.protobuf.Int64Value max_enqueued_batches = 3;
  if (this->has_max_enqueued_batches()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *max_enqueued_batches_);
  }

  // .google.protobuf.Int64Value num_batch_threads = 4;
  if (this->has_num_batch_threads()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *num_batch_threads_);
  }

  // .google.protobuf.StringValue thread_pool_name = 5;
  if (this->has_thread_pool_name()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *thread_pool_name_);
  }

  // .google.protobuf.BoolValue enable_large_batch_splitting = 8;
  if (this->has_enable_large_batch_splitting()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *enable_large_batch_splitting_);
  }

  // .google.protobuf.Int64Value max_execution_batch_size = 9;
  if (this->has_max_execution_batch_size()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *max_execution_batch_size_);
  }

  // bool pad_variable_length_inputs = 7;
  if (this->pad_variable_length_inputs() != 0) {
    total_size += 1 + 1;
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void BatchingParameters::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.BatchingParameters)
  GOOGLE_DCHECK_NE(&from, this);
  const BatchingParameters* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const BatchingParameters>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.BatchingParameters)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.BatchingParameters)
    MergeFrom(*source);
  }
}

void BatchingParameters::MergeFrom(const BatchingParameters& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.BatchingParameters)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  allowed_batch_sizes_.MergeFrom(from.allowed_batch_sizes_);
  if (from.has_max_batch_size()) {
    mutable_max_batch_size()->::google::protobuf::Int64Value::MergeFrom(from.max_batch_size());
  }
  if (from.has_batch_timeout_micros()) {
    mutable_batch_timeout_micros()->::google::protobuf::Int64Value::MergeFrom(from.batch_timeout_micros());
  }
  if (from.has_max_enqueued_batches()) {
    mutable_max_enqueued_batches()->::google::protobuf::Int64Value::MergeFrom(from.max_enqueued_batches());
  }
  if (from.has_num_batch_threads()) {
    mutable_num_batch_threads()->::google::protobuf::Int64Value::MergeFrom(from.num_batch_threads());
  }
  if (from.has_thread_pool_name()) {
    mutable_thread_pool_name()->::google::protobuf::StringValue::MergeFrom(from.thread_pool_name());
  }
  if (from.has_enable_large_batch_splitting()) {
    mutable_enable_large_batch_splitting()->::google::protobuf::BoolValue::MergeFrom(from.enable_large_batch_splitting());
  }
  if (from.has_max_execution_batch_size()) {
    mutable_max_execution_batch_size()->::google::protobuf::Int64Value::MergeFrom(from.max_execution_batch_size());
  }
  if (from.pad_variable_length_inputs() != 0) {
    set_pad_variable_length_inputs(from.pad_variable_length_inputs());
  }
}

void BatchingParameters::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.BatchingParameters)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void BatchingParameters::CopyFrom(const BatchingParameters& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.BatchingParameters)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool BatchingParameters::IsInitialized() const {
  return true;
}

void BatchingParameters::Swap(BatchingParameters* other) {
  if (other == this) return;
  InternalSwap(other);
}
void BatchingParameters::InternalSwap(BatchingParameters* other) {
  using std::swap;
  allowed_batch_sizes_.InternalSwap(&other->allowed_batch_sizes_);
  swap(max_batch_size_, other->max_batch_size_);
  swap(batch_timeout_micros_, other->batch_timeout_micros_);
  swap(max_enqueued_batches_, other->max_enqueued_batches_);
  swap(num_batch_threads_, other->num_batch_threads_);
  swap(thread_pool_name_, other->thread_pool_name_);
  swap(enable_large_batch_splitting_, other->enable_large_batch_splitting_);
  swap(max_execution_batch_size_, other->max_execution_batch_size_);
  swap(pad_variable_length_inputs_, other->pad_variable_length_inputs_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
}

::google::protobuf::Metadata BatchingParameters::GetMetadata() const {
  protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::file_level_metadata[kIndexInFileMessages];
}


// @@protoc_insertion_point(namespace_scope)
}  // namespace serving
}  // namespace tensorflow
namespace google {
namespace protobuf {
template<> GOOGLE_PROTOBUF_ATTRIBUTE_NOINLINE ::tensorflow::serving::ModelWarmupOptions* Arena::CreateMaybeMessage< ::tensorflow::serving::ModelWarmupOptions >(Arena* arena) {
  return Arena::CreateInternal< ::tensorflow::serving::ModelWarmupOptions >(arena);
}
template<> GOOGLE_PROTOBUF_ATTRIBUTE_NOINLINE ::tensorflow::serving::SessionBundleConfig* Arena::CreateMaybeMessage< ::tensorflow::serving::SessionBundleConfig >(Arena* arena) {
  return Arena::CreateInternal< ::tensorflow::serving::SessionBundleConfig >(arena);
}
template<> GOOGLE_PROTOBUF_ATTRIBUTE_NOINLINE ::tensorflow::serving::BatchingParameters* Arena::CreateMaybeMessage< ::tensorflow::serving::BatchingParameters >(Arena* arena) {
  return Arena::CreateInternal< ::tensorflow::serving::BatchingParameters >(arena);
}
}  // namespace protobuf
}  // namespace google

// @@protoc_insertion_point(global_scope)
